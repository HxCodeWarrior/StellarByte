# : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 
#  文件: pretrain_config.yaml
#  说明: Byte‑Transformer 预训练/继续训练的统一配置
#        ├─ 一级键 :  功能模块
#        └─ 二级键 :  具体超参
#  ⚠️注意：YAML 规范要求键和值之间必须有一个空格
#         可按需增删；键名若改动，记得调整代码中的读取逻辑
#         参数命名不可冲突，若有一致推荐：上一级前缀+参数命
# : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 

# 实验配置
experiment:
  # : : : : : : : : : : : 
  # 注意：1. 如果要启用SwanLab记录，必须启用use_swanlab，设置为True
  #      2. 如果要启用SwanLab云模式，需要设置mode: 'cloud'或者'mode: cloud-only'，同时也需要填入api_key
  #      3. 如果要启用SwanLab本地模式，需要设置mode: 'local',同时需要配置logdir(如果不配置会自动生成)，不需要配置api_key
  #      4. 详细请参考：https://docs.swanlab.cn/guide_cloud/general/what-is-swanlab.html
  # 项目名可设置为None使用随机字符串，建议不设置以使用随机生成字符串
  # : : : : : : : : : : : 
  use_swanlab: False               # 是否启用swanlab
  project_name: "ByteLM-Pretrain"  # 项目名称
  run_name: "baseline-158M"        # 实验运行名称
  mode: "cloud"                    # SwanLab记录模式: 'cloud','cloud-only','local','disabled'
  logdir: "./swanlab_run"          # SwanLab记录日志保存路径
  api_key: ""                      # SwanLab API密钥

# 数据配置
data:
  tokenizer_path: "./tokenizer"  # 分词器路径
  train_data: "./datasets/test/test_train.jsonl" # 训练数据目录
  eval_data: "./datasets/test/test_eval.jsonl"   # 验证数据目录

# 模型架构配置
model:
  # 基础参数
  vocab_size: 32768             # 词汇表大小
  dim: 768                      # 模型隐藏层维度
  num_layers: 12                # Transformer层数
  max_seq_len: 2048             # 最大序列长度
  norm_eps: 1e-6                # LayerNorm的epsilon
  rope_theta: 10000.0           # RoPE位置编码基数
  
  # 注意力机制
  attention:
    num_heads: 16               # 注意力头总数
    num_kv_heads: 8             # Key/Value头数(分组查询注意力)
    enabled_flash_attn: False   # 是否启用FlashAttention
    attention_dropout: 0.0      # 注意力权重Dropout概率
    max_batch_size: 32          # 最大批次大小
  
  # 前馈网络
  feed_forward:
    multiple_of: 256             # 前馈层维度倍数
    ffn_dim_multiplier: null     # 隐藏层维度计算倍数
    ffn_dropout: 0.1             # FeedForward层Dropout概率
  
  # MoE专家网络
  moe:
    enabled_moe: false            # 是否启用Mixture of  Experts (原名 moe_enabled)
    num_experts_per_tok: 2        # 每个token选择的专家数 (原名   moe_k)
    num_routed_experts: 4         # 路由专家数量 (原名  moe_num_experts)
    num_shared_experts: 1         # 共享专家数量
    scoring_func: "softmax"       # 专家选择函数
    aux_loss_alpha: 0.01          # 辅助损失系数 (原名  moe_loss_coefficient)
    seq_aux: true                 # 序列级辅助损失
    norm_topk_prob: true          # 标准化top-k概率
    gating_dim: 768               # 门控网络维度, 与dim保持一致
  
  # 正则化
  regularization:
    resid_dropout: 0.1            # 残差连接Dropout概率
  
  # KVCache机制
  kv_cache:
    enabled_kvcache: False        # 是否启用KVCache
    
  # 并行
  parallel:
    model_parallel_size: 1        # 模型并行组大小

# 训练配置
training:
  # 基础参数
  train_epochs: 10               # 训练总轮次
  learning_rate: 3e-4            # 初始学习率
  min_lr_ratio: 0.1              # 最小学习率比例
  weight_decay: 0.1              # 权重衰减系数

  # 数据集加载器
  use_streaming: False           # 是否使用数据流式训练
  batch_size: 32                 # 单卡每批数据量
  steps_per_epoch: 100           # 每个Epoch的步数(数据集流式加载必须配置)【计算：steps_per_epoch = num_total_data / (battch_size * gradient_accumulation_steps)】

  # 优化器
  beta1: 0.9                     # AdamW beta1
  beta2: 0.98                    # AdamW beta2
  
  # 学习率调度
  warmup_ratio: 0.02             # Warmup阶段比例
  plateau_ratio: 0.01            # 学习率平台期比例
  
  # 梯度处理
  gradient_accumulation_steps: 4 # 梯度累积步数 【effective_batch_size = batch_size * gradient_accumulation_steps * world_size】
  max_grad_norm: 1.0             # 梯度裁剪阈值
  
  # 资源管理
  num_workers: 8                 # 数据加载线程数
  use_cuda: True                 # 是否使用GPU
  world_size: 1                  # 分布式训练进程数
  rank: 0                        # 分布式训练进程rank
  device: "cpu"                  # 设备名称：cpu / cuda:0 / cuda:1 / cuda:[0,1]
  mixed_precision: True          # 是否使用混合精度

# 早停机制设置
early_stop:
  patience: 3                      # 早停次数
  patience_monitor: "loss"         # 需要监控的指标,默认验证损失，可选：loss / accuracy
  patience_mode: "min"             # 监控指标模式: max / min,若为 min 则 metric 越小越好停
  patience_delta: 0.0001           # 最小提升幅度，小于该幅度视为无提升

# 检查点设置
checkpoints:
  checkpoints_dir: "./checkpoints" # 输出目录
  checkpoints_monitor: "loss"      # 最佳监控指标
  checkpoints_mode: "min"          # 监控指标模式: max / min,若为 min 则 metric 越小越好
  max_checkpoints: 10              # 保存最多数量
  checkpoints_prefix: "Stellar"    # 检查点名前缀
  keep_last_n: 1                   # 强制保留最近 N 个 checkpoint（会与 max_checkpoints 一起工作）
  is_master: True                  # 是否为主进程，若在分布式训练中，应传入是否为主进程（rank0）。None 表示非分布式（主进程）
  resume_training: True            # 是否在已存在的 checkpoint 上继续训练
  save_epochs: 1                   # 保存间隔(轮次)
  save_interval: 1000              # 保存间隔(步数)
  
  # 日志与评估
save:
  log_interval: 50               # 日志记录间隔(步数)
  eval_steps: 500                # 评估间隔(步数)
  eval_batch_size: 16            # 评估批次大小

# 生成配置(推理时使用)
generation:
  temperature: 1.0               # 采样温度
  top_k: 50                      # Top-k采样
  top_p: 0.9                     # Top-p采样
  repetition_penalty: 1.2        # 重复惩罚因子
  repetition_context: 512        # 重复惩罚上下文长度

# 日志配置
logger:
  logger_name: "StellarByte"            # 自定义logger名字，可为None使用root logger
  log_dir: "logs"                       # 日志文件保存目录
  log_file: "StellarByte_pretrain.log"  # 日志文件名
  log_level: "DEBUG"                    # logger总体日志等级
  console_level: "INFO"                 # 控制台日志等级
  file_level: "DEBUG"                   # 文件日志等级
  use_color: True                       # 控制台启用彩色日志
  rotation: "midnight"                  # 文件轮转周期，午夜
  backup_count: 7                       # 保留最近7个日志文件
  is_rank_0: True                       # 是否为rank 0（多进程场景控制文件写入）
