# : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 
#  文件: pretrain_config.yaml
#  说明: Byte‑Transformer 预训练/继续训练的统一配置
#        ├─ 一级键 :  功能模块
#        └─ 二级键 :  具体超参
#  ⚠️注意：YAML 规范要求键和值之间必须有一个空格
#         可按需增删；键名若改动，记得调整代码中的读取逻辑
#         参数命名不可冲突，若有一致推荐：上一级前缀+参数命
# : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : 

# 实验配置
experiment:
  # : : : : : : : : : : : 
  # 注意：1. 如果要启用SwanLab记录，必须启用use_swanlab，设置为True
  #      2. 如果要启用SwanLab云模式，需要设置mode: 'cloud'或者'mode: cloud-only'，同时也需要填入api_key
  #      3. 如果要启用SwanLab本地模式，需要设置mode: 'local',同时需要配置logdir(如果不配置会自动生成)，不需要配置api_key
  #      4. 详细请参考：https://docs.swanlab.cn/guide_cloud/general/what-is-swanlab.html
  # 项目名可设置为None使用随机字符串，建议不设置以使用随机生成字符串
  # : : : : : : : : : : : 
  use_swanlab: False               # 是否启用swanlab
  project_name: "ByteLM-Pretrain"  # 项目名称
  run_name: "baseline-158M"        # 实验运行名称
  mode: "cloud"                    # SwanLab记录模式: 'cloud','cloud-only','local','disabled'
  logdir: "./swanlab_run"          # SwanLab记录日志保存路径
  api_key: ""                      # SwanLab API密钥

# 数据配置
data:
  tokenizer_path: "./tokenizer"  # 分词器路径
  train_data: "./datasets/test/test_train.jsonl" # 训练数据目录
  eval_data: "./datasets/test/test_eval.jsonl"   # 验证数据目录

# 模型架构配置
model:
  # 基础参数
  vocab_size: 32768             # 词汇表大小
  model_dim: 768                # 模型隐藏层维度
  num_layers: 12                # Transformer层数
  max_seq_len: 2048             # 最大序列长度
  layer_norm_eps: 1e-5          # LayerNorm的epsilon值
  initializer_range: 0.02       # 权重初始化标准差
  layerscale_init: 1e-5         # 层缩放参数γ的初始值
  parallel_residual: true       # 是否使用并行残差连接
  
  # 注意力机制
  attention:
    num_heads: 16               # 注意力头总数
    num_kv_heads: 8             # Key/Value头数(分组查询注意力)
    use_flash_attention: false  # 是否启用FlashAttention
    attention_window_size: 0    # 滑动窗口大小(0: 全局注意力)
    attention_dropout_prob: 0.1 # 注意力权重Dropout概率
    base_theta: 10000.0         # RoPE位置编码基数
    ntk_alpha: 1.0              # NTK动态缩放因子
    use_cache: true             # 是否启用KV缓存
    key_cache_dtype: float16    # Key缓存数据类型
    value_cache_dtype: float16  # Value缓存数据类型
  
  # 前馈网络
  feed_forward:
    hidden_dim: 3072            # MLP隐藏层维度(4*model_dim)
    dim_multiplier: 4           # 隐藏层维度计算倍数
    hidden_dropout_prob: 0.1    # MLP层Dropout概率
  
  # 正则化
  regularization:
    residual_dropout_prob: 0.1  # 残差连接Dropout概率
    drop_path_prob: 0.0         # DropPath最大丢弃概率
  
  # 张量并行
  parallel:
    tensor_parallel_size: 1     # 张量并行组大小

# 训练配置
training:
  # 基础参数
  train_epochs: 10               # 训练总轮次
  batch_size: 32                 # 每批数据量
  learning_rate: 3e-4            # 初始学习率
  min_lr_ratio: 0.1              # 最小学习率比例
  weight_decay: 0.1              # 权重衰减系数
  
  # 优化器
  beta1: 0.9                     # AdamW beta1
  beta2: 0.98                    # AdamW beta2
  
  # 学习率调度
  warmup_ratio: 0.02             # Warmup阶段比例
  plateau_ratio: 0.01            # 学习率平台期比例
  
  # 梯度处理
  gradient_accumulation_steps: 4 # 梯度累积步数
  max_grad_norm: 1.0             # 梯度裁剪阈值
  
  # 资源管理
  num_workers: 8                 # 数据加载线程数
  use_cuda: true                 # 是否使用GPU
  device: "cpu"                  # 设备名称：cpu / cuda:0 / cuda:1 / cuda:[0,1]
  mixed_precision: true          # 是否使用混合精度

# 早停机制设置
early_stop:
  patience: 3                      # 早停次数
  patience_monitor: "loss"         # 需要监控的指标,默认验证损失，可选：loss / accuracy
  patience_mode: "min"             # 监控指标模式: max / min,若为 min 则 metric 越小越好停
  patience_delta: 0.0001           # 最小提升幅度，小于该幅度视为无提升

# 检查点设置
checkpoints:
  checkpoints_dir: "./checkpoints" # 输出目录
  checkpoints_monitor: "loss"      # 最佳监控指标
  checkpoints_mode: "min"          # 监控指标模式: max / min,若为 min 则 metric 越小越好
  max_checkpoints: 10              # 保存最多数量
  checkpoints_prefix: "Stellar"    # 检查点名前缀
  keep_last_n: 1                   # 强制保留最近 N 个 checkpoint（会与 max_checkpoints 一起工作）
  is_master: True                  # 是否为主进程，若在分布式训练中，应传入是否为主进程（rank0）。None 表示非分布式（主进程）
  resume_training: True            # 是否在已存在的 checkpoint 上继续训练
  save_epochs: 1                   # 保存间隔(轮次)
  save_interval: 1000              # 保存间隔(步数)
  
  # 日志与评估
save:
  log_interval: 50               # 日志记录间隔(步数)
  eval_steps: 500                # 评估间隔(步数)
  eval_batch_size: 16            # 评估批次大小

# 生成配置(推理时使用)
generation:
  temperature: 1.0               # 采样温度
  top_k: 50                      # Top-k采样
  top_p: 0.9                     # Top-p采样
  repetition_penalty: 1.2        # 重复惩罚因子
  repetition_context: 512        # 重复惩罚上下文长度

# 日志配置
logger:
  logger_name: "StellarByte"            # 自定义logger名字，可为None使用root logger
  log_dir: "logs"                       # 日志文件保存目录
  log_file: "StellarByte_pretrain.log"  # 日志文件名
  log_level: "DEBUG"                    # logger总体日志等级
  console_level: "INFO"                 # 控制台日志等级
  file_level: "DEBUG"                   # 文件日志等级
  use_color: True                       # 控制台启用彩色日志
  rotation: "midnight"                  # 文件轮转周期，午夜
  backup_count: 7                       # 保留最近7个日志文件
  is_rank_0: True                       # 是否为rank 0（多进程场景控制文件写入）
