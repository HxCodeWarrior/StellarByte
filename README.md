<div align="center">

# âœ¨ StellarByte âœ¨

<p>æŠŠæ¯ä¸ªå­—èŠ‚éƒ½ç‚¹äº®æˆä¸€ç›ç¯ï¼Œç…§è§å¤ä»ŠåŒæœ›çš„å¤œç©ºã€‚</p>

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue?style=flat-square&logo=python)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange?style=flat-square&logo=pytorch)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)](LICENSE)
[![HuggingFace](https://img.shields.io/badge/ğŸ¤—-HuggingFace-yellow?style=flat-square)](https://huggingface.co/)
[![Blog](https://img.shields.io/badge/Blog-ByteWyrm-pink?style=flat-square)](https://blog.devnest.top/)

</div>

## ğŸ“š ç®€ä»‹

StellarByte æ˜¯ä¸€ä¸ªåŸºäº Transformer æ¶æ„çš„é«˜æ€§èƒ½è¯­è¨€æ¨¡å‹å®ç°ï¼Œä¸ HuggingFace ç”Ÿæ€å®Œå…¨å…¼å®¹ã€‚è¯¥é¡¹ç›®èåˆäº†å¤šç§ç°ä»£ Transformer ä¼˜åŒ–æŠ€æœ¯ï¼Œæ—¨åœ¨æä¾›é«˜æ•ˆã€çµæ´»ä¸”æ˜“äºä½¿ç”¨çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œé€‚ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†å’Œç”Ÿæˆå¼ AI ä»»åŠ¡ã€‚

## âœ¨ ç‰¹æ€§

- ğŸš€ **é«˜æ€§èƒ½å®ç°**ï¼šé›†æˆ FlashAttentionã€KV ç¼“å­˜ç­‰ä¼˜åŒ–æŠ€æœ¯
- ğŸ§© **æ¨¡å—åŒ–è®¾è®¡**ï¼šå„ç»„ä»¶å¯ç‹¬ç«‹ä½¿ç”¨æˆ–ç»„åˆ
- ğŸ”„ **Dynamic-RoPE æ—‹è½¬ä½ç½®ç¼–ç **ï¼šæ”¹è¿›çš„ RoPE ä½ç½®ç¼–ç ï¼Œæé«˜é•¿åºåˆ—å»ºæ¨¡èƒ½åŠ›
- ğŸ› ï¸ **ä¸°å¯Œçš„ä¼˜åŒ–æŠ€æœ¯**ï¼š
  - âš™ï¸ DeepNorm å½’ä¸€åŒ–ç­–ç•¥
  - ğŸ” LayerScale åˆå§‹åŒ–æŠ€æœ¯
  - ğŸ”€ DropPath æ­£åˆ™åŒ–
  - âš¡ å¹¶è¡Œæ®‹å·®è¿æ¥
- ğŸ“Š **å‚æ•°é«˜æ•ˆå¾®è°ƒ**ï¼šå†…ç½® LoRA ä½ç§©é€‚åº”å®ç°
- ğŸ¤— **HuggingFace å…¼å®¹**ï¼šæ— ç¼é›†æˆ Transformers ç”Ÿæ€ç³»ç»Ÿ
- ğŸ“ **æ¸…æ™°çš„ä»£ç ç»“æ„**ï¼šæ˜“äºç†è§£å’Œæ‰©å±•

## ğŸ“š æ¨¡å‹ç»“æ„
> [æ¨¡å‹æ¶æ„](./model_info/model_structure.md)

## ğŸ”§ å®‰è£…

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- PyTorch 2.5.1+
- CUDA 11.8+ (GPUåŠ é€Ÿï¼Œå¯é€‰)

### å®‰è£…æ­¥éª¤

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/HxCodeWarrior/StellarByte.git
cd StellarByte

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å¦‚æœéœ€è¦å¼€å‘ç¯å¢ƒ
pip install -r requirements.txt[dev]

# å®‰è£…å¼€å‘ç‰ˆæœ¬ï¼ˆæš‚æœªå®ç°ï¼‰
# pip install -e .
```

### ä¾èµ–è¯´æ˜

é¡¹ç›®ä¾èµ–å·²æŒ‰åŠŸèƒ½æ¨¡å—åˆ†ç±»æ•´ç†ï¼š

- **æ ¸å¿ƒä¾èµ–**ï¼šPyTorchã€Transformersã€æ•°æ®å¤„ç†åº“
- **æ¨¡å‹ç»„ä»¶**ï¼šä½ç½®ç¼–ç ã€æ³¨æ„åŠ›æœºåˆ¶ç­‰å®ç°
- **å¯è§†åŒ–ä¸ç›‘æ§**ï¼šå®éªŒè¿½è¸ªã€æŒ‡æ ‡å¯è§†åŒ–
- **æµ‹è¯•ä¸å¼€å‘**ï¼šå•å…ƒæµ‹è¯•ã€ç±»å‹æ£€æŸ¥
- **åˆ†å¸ƒå¼è®­ç»ƒ**ï¼šå¤šGPU/å¤šèŠ‚ç‚¹è®­ç»ƒæ”¯æŒ
- **æ€§èƒ½ä¼˜åŒ–**ï¼šå†…å­˜ä¼˜åŒ–ã€è®¡ç®—åŠ é€Ÿ


## ğŸš€ å¿«é€Ÿå¼€å§‹

```python
import torch
from stellarbyte import ByteModel, ByteConfig

# åˆ›å»ºé…ç½®
config = ByteModelConfig(
    vocab_size=32000,
    hidden_size=768,
    num_hidden_layers=12,
    num_attention_heads=12,
    intermediate_size=3072
)

# åˆå§‹åŒ–æ¨¡å‹
model = ByteModel(config)

# å‡†å¤‡è¾“å…¥
inputs = torch.randint(0, 32000, (1, 512))

# å‰å‘ä¼ æ’­
outputs = model(inputs)
```

## ğŸ“‹ ä½¿ç”¨ç¤ºä¾‹

### ä» HuggingFace åŠ è½½é¢„è®­ç»ƒæ¨¡å‹(æš‚æœªå®ç°)

```python
from stellarbyte import ByteTransformer
from transformers import AutoTokenizer

# åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
model = ByteTransformer.from_pretrained("path/to/model")
tokenizer = AutoTokenizer.from_pretrained("path/to/tokenizer")

# ç¼–ç æ–‡æœ¬
inputs = tokenizer("æŠŠæ¯ä¸ªå­—èŠ‚éƒ½ç‚¹äº®æˆä¸€ç›ç¯", return_tensors="pt")

# ç”Ÿæˆæ–‡æœ¬
outputs = model.generate(inputs.input_ids, max_length=100)
print(tokenizer.decode(outputs[0]))
```

### ä½¿ç”¨ LoRA è¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒ(æš‚æœªæ—¶é—´)

```python
from stellarbyte import ByteTransformer, LoRAConfig
from stellarbyte.lora import apply_lora_to_model

# åŠ è½½åŸºç¡€æ¨¡å‹
model = ByteTransformer.from_pretrained("path/to/model")

# é…ç½® LoRA
lora_config = LoRAConfig(
    r=8,
    target_modules=["q_proj", "v_proj"],
    lora_alpha=16,
    lora_dropout=0.05
)

# åº”ç”¨ LoRA åˆ°æ¨¡å‹
model = apply_lora_to_model(model, lora_config)

# ç°åœ¨åªæœ‰ LoRA å‚æ•°ä¼šè¢«æ›´æ–°
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
StellarByte/
|   .gitignore
|   CONTRIBUTING.md
|   datasets.py
|   INSTALL.md
|   LICENSE
|   model_pretrain.py
|   model_stf_train.py
|   README.md
|   requirements.txt
|   setup.py
|   tokenizer_pretrain.py
|
+---.pytest_cache
|   |   .gitignore
|   |   CACHEDIR.TAG
|   |   README.md
|   |
|   \---v
|       \---cache
|               lastfailed
|               nodeids
|               stepwise
|
+---checkpoints
+---configs
|       model_pretrain.yaml
|
+---datasets
|   |   data_preprocessor.py
|   |   train.jsonl
|   |   eval.jsonl
|   |
|   +---test
|   |       test_eval.jsonl
|   |       test_train.jsonl
|   |
|   \---tokenizers
|           code.jsonl
|           emoji.jsonl
|           en.jsonl
|           multi_lang.jsonl
|           zh.jsonl
|
+---logs
|
+---model
|   |   Attention.py
|   |   config.py
|   |   DecoderLayer.py
|   |   EmbeddingLayer.py
|   |   MLP.py
|   |   Model.py
|   |   MoELayer.py
|   |   MoERouter.py
|   |   Position_Embedding.py
|   |   RMSNorm.py
|   |   __init__.py
|   |
|   +---utils
|           DropPath.py
|           KVCache.py
|           LoRA.py
|           __init__.py
|        
|    
+---model_info
|   |   model_report_xxx.md
|   |   model_structure.md
|   |
|   \---plots
|
+---scripts
|       setup_env.bat
|       setup_env.py
|       setup_env.sh
|
+---sources
|   \---corpora
|           omw-1.4.zip
|           wordnet.zip
|
+---test
|       test_Attention.py
|       test_datasets.py
|       test_DeocoderLayer.py
|       test_KVCache.py
|       test_LoRA.py
|       test_MLP.py
|       test_MoERouter.py
|       test_Position_Embedding.py
|       test_RMSNorm.py
|    
|
+---tokenizer
|       special_tokens_map.json
|       tokenizer.json
|       tokenizer_config.json
|
+---utils
        checkpoint.py
        config_params.py
        logger.py
        model_info.py
        progressbar.py

```

## ğŸ”œ å¼€å‘è®¡åˆ’

<details> 
<summary>2025.7.13</summary>

### Done:
1. å®ç°BaseModelConfigç±»ï¼Œåç»­çš„è¶…å‚æ•°å°†é€æ¸è¿­ä»£
2. å®ç°RMSNormå±‚å½’ä¸€åŒ–ç±»
3. Transformerç»å…¸çš„MultiHeadAttentionç±»

### TODOï¼š
1. Attentionåº”ç”¨KVç¼“å­˜ï¼Œæ·»åŠ é‡åŒ–æœºåˆ¶
2. æ„å»ºåŸºç¡€MLPå±‚
3. æ„å»ºåŸºç¡€DecoderLayerå±‚

</details>

---

<details> 
<summary>2025.7.14</summary>

### Done:
1. å®ç°Attentionåº”ç”¨ç¼“å­˜æœºåˆ¶
2. å®ç°Attentioné‡åŒ–æœºåˆ¶
3. å®ç°åŸºç¡€MLPå±‚
4. å®ç°åŸºç¡€ByteDecoderLayerå±‚
5. å®ç°LoRA
6. å®ç°DropPath
7. å®ç°KVCacheæœºåˆ¶
8. é‡å†™äº†Attentionä¸­ä¸KVCacheç›¸å…³çš„éƒ¨åˆ†
9. å®ç°æ¨¡å‹è®­ç»ƒä¸­çš„å·¥å…·ç»„ä»¶
- æ—¥å¿—è®°å½•ç»„ä»¶
- ç‚«é…·è¿›åº¦æ¡åŠ è½½ç»„ä»¶
- æ¨¡å‹æƒé‡ç®¡ç†ç»„ä»¶
- æ¨¡å‹ä¿¡æ¯åˆ†æç»„ä»¶
10. å®ç°æ¨¡å‹è®­ç»ƒæ•°æ®é›†åŠ è½½å™¨åŒ…æ‹¬é¢„è®­ç»ƒæ•°æ®é›†åŠ è½½å™¨å’ŒSTFè®­ç»ƒæ•°æ®é›†åŠ è½½å™¨
10. åŸºæœ¬æ„å»ºæ¨¡å‹é¢„è®­ç»ƒæµç¨‹

### TODO:
1. æ„é€ Memoryç±»å¹¶è¿›è¡Œåº”ç”¨
2. åº”ç”¨LoRAç±»
3. æ„é€ å•æ­¥æ¨ç†æ¥å£ def forward_step(self, x_t, past_k, past_v) -> (out, new_k, new_v)
4. Xposä½ç½®ç¼–ç ä¼˜åŒ–
- ç»“æ„æ€§æ­£åˆ™
- åŠ¨æ€thetaè°ƒæ•´
5. Attention
- num_rep æœªè¢«ä½¿ç”¨ 
- å®ç°â€¯çº¿ç¨‹å¹¶è¡Œ/Allâ€‘Reduce
- è¿›ä¸€æ­¥èåˆFlashAttention-2
- çº¿æ€§å±‚é‡åŒ–quantize() ä½¿ç”¨äº† torch.quantization.quantize_dynamic()ï¼Œä½†è¿™ä»…é™äºçº¿æ€§å±‚ + æ¨ç†ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ä»¥æ”¯æŒGPTQ/AWQ/SmoothQuant
6. KVCache
å°† KVCache.append() æ”¹ä¸ºæ”¯æŒï¼š
- æ»‘çª—ï¼ˆsliding windowï¼‰æˆªæ–­
- å†™å…¥ä½ç½®å¹¶å‘é”å®šï¼ˆif multi-threadï¼‰
- Layer-wise tokenä½ç½®è‡ªåŠ¨åç§»è®¡ç®—

</details>

---

<details>
<summary>2025.7.15</summary>

### Done:
1. æ„å»ºå¹¶ä¼˜åŒ–æ¨¡å‹è®­ç»ƒç»„ä»¶ï¼š
- æ£€æŸ¥ç‚¹ç®¡ç†ç»„ä»¶
- æ„å¤–ä¸­æ–­ä¿æŠ¤ç»„ä»¶
2. å®ç°LLMçš„è®°å¿†ç®¡ç†æœºåˆ¶
3. å®ç°å•æ­¥æ¨ç†æ¥å£ä»¥åŠç›¸å…³ç»„ä»¶
4. åœ¨æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­åº”ç”¨æ£€æŸ¥ç‚¹ç®¡ç†ä»¥åŠæ„å¤–ä¸­æ–­ä¿æŠ¤ç»„ä»¶
5. å…³äºLoRA
- ä¼˜åŒ–LoRAï¼šæ”¯æŒçƒ­æ’æ‹”ã€æ­£åˆ™ä¼˜åŒ–ã€å‡å°‘å†…å­˜å ç”¨æå‡é€Ÿåº¦
- æµ‹è¯•LoRA
6. ä¼˜åŒ–ä½ç½®ç¼–ç 
- ç§»é™¤æ—‹è½¬ä½ç½®ç¼–ç çš„æœ¬åœ°ç¼“å­˜ï¼Œæ”¹ç”¨å…¨å±€ç¼“å­˜ç±»RotaryCache
- æ·»åŠ å¯å­¦ä¹ çš„ç¼©æ”¾å› å­å‚æ•°åˆ°XPosRotaryEmbedding
7. ç»Ÿä¸€äº†Attentionéƒ¨åˆ†çš„paramå‚æ•°dtypeå’Œæœ¬å±‚è®¡ç®—æ•°æ®dtype
- ç»Ÿä¸€è®¡ç®—ç²¾åº¦ä¸ºfloat32ä»¥æé«˜æ•°å€¼ç¨³å®šæ€§
8. KVCacheæ·»åŠ æ»‘åŠ¨çª—å£æˆªæ–­å¤„ç†

### TODOï¼š
1. LoRAè¿›ä¸€æ­¥ä¼˜åŒ–
- éçº¿æ€§LoRA
- æ”¯æŒConv2d/Transformer.Conv1dæ³¨å…¥
- é€‚é…é‡åŒ–æ¨¡å—
- Tunerå†»ç»“å±‚é€‰æ‹©ç­–ç•¥
2. Attention:
- å®ç°çº¿ç¨‹å¹¶è¡Œ/Allâ€‘Reduce
- è¿›ä¸€æ­¥èåˆFlashAttention-2
3. æµ‹è¯•
- æµ‹è¯•æ•°æ®é›†åŠ è½½å™¨
- æµ‹è¯•LoRA
- æµ‹è¯•Attention
- æµ‹è¯•Memory

### DEBUG
1. å·¥å…·è„šæœ¬åˆ†ææ¨¡å‹ä¿¡æ¯æŠ¥é”™

</details>

---

<details>
<summary>2025.7.16</summary>

### Done:
1. å®ç°åˆ†å¸ƒå¼å¤šå¡è®­ç»ƒ
2. å®ç°å¼ é‡/æ¨¡å‹å¹¶è¡Œ
3. æ•´åˆæ¨¡å‹è®­ç»ƒå‚æ•°ï¼Œå¹¶æ„é€ å‚æ•°è¯»å–å™¨
4. ä¼˜åŒ–æ˜¾å­˜å ç”¨ã€æå‡ååé€Ÿåº¦
- æ–°å¢å¯æ§æ¢¯åº¦æ£€æŸ¥ç‚¹
- æŒ‡å®šstepåæ¸…ç†æ— ç”¨ç°å­˜
- æ–°å¢FlashAttentionå¯æ§å¼€å…³
5. Attention å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ä¼˜åŒ–
- è¿›ä¸€æ­¥èåˆFlashAttention-2
- æ–°å¢æ¨¡å‹/å¼ é‡å¹¶è¡Œå¤„ç†
6. æ¨¡å‹åˆ†æè„šæœ¬ model_info.py ä¿®å¤å¦‚ä¸‹é—®é¢˜ï¼š
- analyze_performance(),æ¯æ¬¡åˆ‡æ¢ batch_size å‰ï¼ŒæŠŠ KVCache æ¸…é›¶å¹¶æŠŠ batch_size è®¾å› Noneï¼Œè®©ä¸‹ä¸€è½® forward è‡ªåŠ¨é‡æ–°åˆ†é…ç¼“å­˜ã€‚
7. æµ‹è¯•è„šæœ¬é€šè¿‡
- Attentionæµ‹è¯•
- datasetsæ•°æ®é›†åŠ è½½å™¨æµ‹è¯•
- LoRAæµ‹è¯•
8. ä¼˜åŒ–æ•°æ®é›†åŠ è½½å™¨
- æ©ç ä»01è½¬æ¢ä¸ºboolç±»å‹
- ä¼˜åŒ–æˆªæ–­å¤„ç†
9. tokenizerä¿®å¤ï¼šå¤„ç†tokenizerçš„padå¡«å……ä¸eos_tokenä¸€æ ·å¯¼è‡´å¡«å……æ··ä¹±ï¼Œåˆ†åˆ«ä½¿ç”¨ç‰¹æ®Šæ ‡è¯†
10. LoRAä¿®å¤å¦‚ä¸‹é—®é¢˜ï¼š
- æƒé‡åˆå¹¶çš„çº¿ç¨‹é”ä½œç”¨åŸŸè¿‡å¤§
- ç¡®ä¿ LoRA å¢é‡è®¡ç®— æ—¶æ•°æ®ç±»å‹ç»Ÿä¸€ä¸ºLoRAç»Ÿä¸€å‚æ•°ç±»å‹self.cfg.dtype or torch.float32
- è§£å†³ LoRAæ³¨å…¥é£é™©ï¼Œæ³¨å…¥å‰åˆ¤æ–­æ¨¡å—æ˜¯å¦å·²ç»æ˜¯ LoRALinearï¼Œè·³è¿‡æ³¨å…¥
- è§£å†³ LoRALinear å†…éƒ¨æƒé‡å¸ƒå±€ä¸ fan_in_fan_out å…³è”ä¸è¶³ é—®é¢˜ï¼Œåœ¨ forward é˜¶æ®µå¢é‡è®¡ç®—æ—¶æ ¹æ® fan_in_fan_out è½¬ç½® LoRA å‚æ•°
- è§£å†³ å¤šé€‚é…å™¨çƒ­åˆ‡æ¢çš„ activate() æœªè§£é™¤æ—§ LoRA æƒé‡å ç”¨æ˜¾å­˜ é—®é¢˜ï¼Œä¿å­˜åŸå§‹å±‚å¼•ç”¨ï¼Œdeactivate æ—¶æ¢å¤åŸå§‹å±‚ï¼Œå½»åº•å¸è½½æ—§ LoRAå±‚
- ä½¿ç”¨ å®‰å…¨ torch.load(), å½“å‰é»˜è®¤ weights_only=Falseï¼Œä½†å®˜æ–¹å·²å®£å¸ƒæœªæ¥ä¼šæ”¹ä¸ºâ€¯Trueï¼Œå› æ­¤æ„å»ºè‡ªåŠ¨æ£€æµ‹æ˜¯å¦ä½¿ç”¨è¯¥å‚æ•°å¯¼å…¥å‡½æ•°
11. KVCacheä¿®å¤å¦‚ä¸‹é—®é¢˜ï¼š
- å½“ T_new >= self.max_T æ¡ä»¶æˆç«‹æ—¶ï¼Œoverflow è¢«èµ‹å€¼äº†ï¼Œä½† current_len æ²¡æœ‰è¢«èµ‹å€¼ã€‚appendå‡½æ•°ä¸­ï¼Œç»™ current_len èµ‹ä¸€ä¸ªåˆå§‹å€¼ï¼Œä¸”æ— è®ºå“ªæ¡åˆ†æ”¯éƒ½ä¿è¯ current_len å·²å®šä¹‰ã€‚
13. ä½¿ç”¨æ¨¡å‹åˆ†æè„šæœ¬å¯¹æ¨¡å‹è¿›è¡Œåˆæ­¥åˆ†æ


### TODO:
1. å®ç°DeepSeed
2. å®ç°åŠ¨æ€å‰ªæ
- AttentionåŠ¨æ€å‰ªæ
- KVCacheåŠ¨æ€å‰ªæ
3. æ•°æ®é›†åŠ è½½å™¨é’ˆå¯¹å¤§æ•°æ®é›†è¿›è¡Œstreamingä¼˜åŒ–
4. æ¨¡å‹åˆ†æè„šæœ¬
- ç»˜å›¾ä¸­æ–‡ä¸æ˜¾ç¤º
- æ¨¡å‹å±‚çº§ç»“æ„åˆ†æä¸é€å½»
- æ·»åŠ æ¨¡å‹å±‚çº§ç»“æ„ç»˜å›¾å¯è§†åŒ–

</details>

---

<details>
<summary>2025.7.17</summary>

### DONE:
1. å¢å¼ºæ¨¡å‹åˆ†ææŠ¥å‘ŠåŠŸèƒ½å¹¶æ·»åŠ å¯è§†åŒ–å›¾è¡¨
- æ·»åŠ ä¸­æ–‡æ”¯æŒï¼Œè§£å†³å›¾è¡¨ä¸­æ–‡ä¹±ç é—®é¢˜
- æ–°å¢æ¨¡å‹ç»“æ„å›¾ã€ç¨€ç–åº¦çƒ­åŠ›å›¾å’Œé›·è¾¾å›¾ç­‰å¯è§†åŒ–åŠŸèƒ½
- æ”¹è¿›æ¨¡å‹æ¶æ„æè¿°æ ¼å¼ï¼Œå¢åŠ æ›´å¤šç»†èŠ‚
- ä¼˜åŒ–å‚æ•°åˆ†å¸ƒé¥¼å›¾æ ·å¼ï¼Œçªå‡ºæ˜¾ç¤ºæœ€å¤§å æ¯”éƒ¨åˆ†
2. é‡æ„æ¨¡å‹è®­ç»ƒç»„ä»¶â€”â€”è¿›åº¦æ¡ç»„ä»¶
- å°†åŸæœ‰çš„ RichProgressBar ç±»é‡æ„ä¸ºæ›´çµæ´»çš„ ProgressBarManager ç±»
- æ”¯æŒè®­ç»ƒå’ŒéªŒè¯é˜¶æ®µçš„å¤šä»»åŠ¡ç®¡ç†
- æ–°å¢éªŒè¯é˜¶æ®µæŒ‡æ ‡æ±‡æ€»è¡¨æ ¼æ˜¾ç¤ºåŠŸèƒ½
- æ”¹è¿›è¿›åº¦æ¡æ ·å¼å’Œäº¤äº’é€»è¾‘
3. é‡æ„æ¨¡å‹è®­ç»ƒç»„ä»¶,é‡æ„è®­ç»ƒå¾ªç¯å’ŒéªŒè¯é€»è¾‘ï¼Œæ”¹è¿›è¿›åº¦ç®¡ç†
- å°† RichProgressBar æ›¿æ¢ä¸ºæ›´é€šç”¨çš„ ProgressBarManager
- åœ¨è®­ç»ƒå’ŒéªŒè¯å¾ªç¯ä¸­æ·»åŠ è¿›åº¦æ¡æ”¯æŒ
- æ”¹è¿›æŒ‡æ ‡è®¡ç®—å’Œæ—¥å¿—è®°å½•ï¼Œæ·»åŠ å‡†ç¡®ç‡ç»Ÿè®¡
- ä¼˜åŒ–è®¾å¤‡ç®¡ç†å’Œåˆ†å¸ƒå¼è®­ç»ƒåˆå§‹åŒ–é€»è¾‘
- è°ƒæ•´ AMP ä¸Šä¸‹æ–‡ç®¡ç†ä»¥æ”¯æŒä¸åŒè®¾å¤‡ç±»å‹
4. ä¼˜åŒ–RMSNormå±‚ï¼Œç§»é™¤ä¸å¿…è¦çš„bufferæ³¨å†Œå¹¶ç®€åŒ–epså¤„ç†
- ä¸å†å°†epsæ³¨å†Œä¸ºbufferï¼Œç›´æ¥ä½œä¸ºtensorå±æ€§ä½¿ç”¨ï¼Œç®€åŒ–ä»£ç ç»“æ„
5. Attentionå¤šå¤´å­æ³¨æ„åŠ›å±‚å…³äºåˆ†å¸ƒå¼è®­ç»ƒè§£å†³éšè—bug
- æ·»åŠ åˆ†å¸ƒå¼åˆå§‹åŒ–æ–¹æ³•å¹¶æ”¹è¿›å¹¶è¡Œé€šä¿¡é€»è¾‘
- æ·»åŠ  init_distributed_mode æ–¹æ³•ç”¨äºæ›´çµæ´»çš„åˆ†å¸ƒå¼ç¯å¢ƒåˆå§‹åŒ–ï¼Œæ”¯æŒä»ç¯å¢ƒå˜é‡æˆ–å‚æ•°è¯»å–é…ç½®
- é‡æ„æ¨¡å‹å¹¶è¡Œé€šä¿¡ç»„çš„åˆå§‹åŒ–é€»è¾‘ï¼Œå¢åŠ å¯¹æœªè®¾ç½®åˆ†å¸ƒå¼å˜é‡çš„é”™è¯¯æ£€æŸ¥
6. datasetsæ•°æ®é›†åŠ è½½å™¨ä¿®å¤æ ‡ç­¾å¼ é‡ä¸­æ©ç æœªæ­£ç¡®åº”ç”¨çš„é—®é¢˜
- åœ¨PretrainDatasetä¸­ï¼Œå½“æ©ç ä¸ºFalseæ—¶ï¼Œå¯¹åº”çš„æ ‡ç­¾å¼ é‡å€¼åº”è®¾ä¸º-100ä»¥é¿å…å½±å“æŸå¤±è®¡ç®—ã€‚æ­¤ä¿®æ”¹ç¡®ä¿äº†æŸå¤±å‡½æ•°ä»…è®¡ç®—æœ‰æ•ˆæ ‡è®°çš„æŸå¤±


### TODO:
1. å…³é”®ç±»æ·»åŠ è°ƒè¯•å‡½æ•°
2. ç»Ÿä¸€æ³¨é‡Šé£æ ¼å¹¶å®Œå–„æ³¨é‡Š
3. ä¿®å¤æ¨¡å‹è®­ç»ƒè„šæœ¬ä¸­çš„é—®é¢˜ï¼š
- æ— æ³•æ˜¾ç¤ºä¸€ä¸ªepochä¸­çš„stepè¿›åº¦
- è‡ªåŠ¨æ„å»ºæˆ–è€…è·å–è™šæ‹Ÿç¯å¢ƒä¿¡æ¯
4. è°ƒè¯•æ¨¡å‹é¢„è®­ç»ƒè„šæœ¬

</details>

---

<details>
<summary>2025.7.18</summary>

### DONE:

1. è®­ç»ƒè„šæœ¬ä¿®å¤å¦‚ä¸‹é—®é¢˜ï¼š
- (1) æ€§èƒ½ä¸è®­ç»ƒæ•ˆç‡çš„é—®é¢˜
  - ä¿®å¤å­¦ä¹ ç‡è°ƒåº¦å™¨è®¡ç®—æ–¹å¼ä¸åˆç†ï¼Œget_lr ä¸­å°† total_iters = len(train_loader) * epochs * (restarts + 1)ï¼Œä½† step å®é™…æ˜¯ per-epoch å†…éƒ¨ stepã€‚è®­ç»ƒä¸­åº”ä½¿ç”¨å…¨å±€ stepï¼ˆglobal_step = epoch * steps_per_epoch + stepï¼‰ï¼Œå¦åˆ™è°ƒåº¦æ›²çº¿ä¸å¹³æ»‘ã€‚
  - ä¿®å¤æ²¡æœ‰æ¢¯åº¦ç´¯è®¡ä¸‹çš„æ­£ç¡®total_stepæ”¯æŒï¼Œåœ¨ get_lr() å’Œ total_iters ä¸­æœªè€ƒè™‘ accumulation_stepsï¼Œå¯¼è‡´è®­ç»ƒå®é™…æ›´æ–°æ­¥æ•°ä¸é¢„æœŸä¸ç¬¦ï¼Œè°ƒåº¦å¤±è¡¡ã€‚
  - å¯ç”¨cudnn.allow.tf32ï¼Œåˆå§‹è®­ç»ƒè„šæœ¬è®¾å®šäº† torch.backends.cuda.matmul.allow_tf32 = Trueï¼Œä½†æ²¡æœ‰è®¾ç½® torch.backends.cudnn.allow_tf32 = Trueã€‚è¿™ä¼šé”™å¤±ä¸€åŠä»¥ä¸Šçš„ TF32 ç®—å­åŠ é€Ÿæœºä¼šã€‚
  - torch.cuda.empty_cache() è°ƒç”¨é¢‘ç¹
- (2) åˆ†å¸ƒå¼è®­ç»ƒçš„é—®é¢˜ï¼Œæ·»åŠ åˆ†å¸ƒå¼è®­ç»ƒ
  - ä¿®å¤ DDPæ—¥å¿—æœªåŠ  rank è¿‡æ»¤ çš„é—®é¢˜ï¼Œè™½ç„¶å¤§å¤šæ•°æ—¥å¿—éƒ½ç”¨ is_main_process() åšäº†åˆ¤æ–­ï¼Œä½†æŸäº›å¼‚å¸¸æ•è·å¦‚ except Exception æˆ– init_distributed() å†…ä»ä¼šå…¨ rank æ‰“å°ï¼Œå»ºè®®ç»Ÿä¸€å°è£…æ—¥å¿—å™¨ã€‚
  - ä¿®å¤ DDPæ¢å¤ä¸å®Œæ•´çš„é—®é¢˜ï¼Œåœ¨æ¢å¤æ¨¡å‹ checkpoint æ—¶ï¼Œstart_step æ²¡æœ‰ç»§ç»­ä½œä¸º global_step ä¼ å…¥ train_epoch()ï¼Œå¯¼è‡´æ–­ç‚¹æ¢å¤è®­ç»ƒæ—¶çš„ LRè°ƒåº¦ã€æ—¥å¿—æ­¥æ•°ã€SwanLab step ä¸å‡†ç¡®ã€‚
- (3) æ˜¾å­˜ç®¡ç†å’Œç¨³å®šæ€§é—®é¢˜
  - ä½¿ç”¨ model.zero_grad(set_to_none=True)ï¼Œæ˜¾å¼ç”¨ set_to_none=True æ›¿æ¢ zero_grad()ï¼Œå¯é‡Šæ”¾æ›´æ—©çš„ grad æ˜¾å­˜ï¼Œæå‡æ˜¾å­˜æ•ˆç‡ã€‚
  - ä¿®å¤ Gradient Checkpoint æœªæŒ‰å±‚ç²’åº¦é…ç½® çš„é—®é¢˜ï¼Œå¯ç”¨äº† model.gradient_checkpointing_enable()ï¼Œä½†è‹¥æ¨¡å‹ç»“æ„è¾ƒæ·±ï¼Œåº”é…åˆé€å±‚æ˜¾å¼è®¾ç½® checkpointing=True çš„ç­–ç•¥ï¼Œæ‰æœ‰å®é™…æ•ˆæœã€‚
- (4) é²æ£’æ€§ä¸å¼‚å¸¸æ¢å¤é—®é¢˜
  - è§£å†³ å¼‚å¸¸æ¢å¤æœªè®°å½• global_step é—®é¢˜ï¼Œæ£€æŸ¥ç‚¹ä¸­åªæœ‰ epoch, stepï¼Œæœªè®°å½• global_stepï¼Œå¯¼è‡´è°ƒåº¦å™¨ä¸æ—¥å¿—é‡å¯åä¸ä¸€è‡´ã€‚
  - è§£å†³ è®­ç»ƒå¼ˆåœºæ•è·æœªç»†åŒ– é—®é¢˜ï¼Œexcept Exception as e: ä¸­æ²¡æœ‰ä½¿ç”¨ traceback.print_exc()ï¼Œæ’æŸ¥é—®é¢˜å›°éš¾ã€‚
- (5)æ·»åŠ  Tokenizer.embedding_sync()ï¼Œæ£€æŸ¥ tokenizer ä¸ embedding å¤§å°æ˜¯å¦åŒæ­¥
- (6)å¢åŠ æ ‡ç­¾å¹³æ»‘æŸå¤±è®¡ç®—å‡½æ•°
- (7)æ·»åŠ CUDAå›¾ä¼˜åŒ–æ ‡è®°
2. RSMNormä¿®å¤ï¼š
- å°†epsä»tensoræ”¹ä¸ºfloatç±»å‹é¿å…é‡å¤è½¬æ¢ï¼Œå‡å°‘å†…å­˜
- å°†epsè½¬æ¢ä¸ºä¸rmsç›¸åŒçš„è®¾å¤‡ä»¥é¿å…è·¨è®¾å¤‡æ“ä½œ
- ç§»é™¤å†—ä½™çš„inv_rmsç±»å‹è½¬æ¢
- ç”¨ torch._dynamo.disable() è£…é¥°å™¨å…³é—­ RMSNorm çš„ forward ç¼–è¯‘ï¼Œé¿å… CUDA Graph å†…å­˜å¤ç”¨å†²çªã€‚
3. Attentionä¿®å¤ï¼š
- æ·»åŠ è‡ªåŠ¨è°ƒæ•´additive_maské•¿åº¦çš„åŠŸèƒ½
- æ–°å¢_adjust_additive_maskæ–¹æ³•ç”¨äºè‡ªåŠ¨å°†additive_maské•¿åº¦ä¸é”®å€¼åºåˆ—å¯¹é½ï¼Œè§£å†³KVç¼“å­˜é•¿åº¦ä¸åŒ¹é…é—®é¢˜
4. Modelä¿®å¤ï¼š
- ä¿®å¤æ³¨æ„åŠ›æ©ç å’Œè®¾å¤‡ç±»å‹ä¸ä¸€è‡´çš„é—®é¢˜å¹¶æ·»åŠ æ¢¯åº¦æ£€æŸ¥ç‚¹
- ä¿®å¤äº†æ³¨æ„åŠ›æ©ç ä¸hidden_statesè®¾å¤‡ç±»å‹ä¸ä¸€è‡´çš„é—®é¢˜ï¼Œå°†æ©ç è½¬æ¢ä¸ºç›¸åŒè®¾å¤‡å’Œç±»å‹ã€‚
- åŒæ—¶æ·»åŠ äº†æ¢¯åº¦æ£€æŸ¥ç‚¹åŠŸèƒ½ä»¥åœ¨è®­ç»ƒæ—¶èŠ‚çœæ˜¾å­˜ï¼Œä½¿ç”¨éé‡å…¥æ–¹å¼æé«˜ç¨³å®šæ€§ã€‚
5. Loggeræ—¥å¿—è®°å½•å™¨å®Œå–„ï¼šä¸ºæ—¥å¿—æ„å»ºå‡½æ•°æ·»åŠ æ§åˆ¶å°æ—¥å¿—çº§åˆ«å‚æ•°
- æ·»åŠ  console_level å‚æ•°ä»¥å…è®¸è‡ªå®šä¹‰æ§åˆ¶å°è¾“å‡ºçš„æ—¥å¿—çº§åˆ«ï¼Œé»˜è®¤ä¿æŒä¸º INFO çº§åˆ«
6. æ›´æ–°é¢„è®­ç»ƒé…ç½®å‚æ•°å’Œæ³¨é‡Šæ ¼å¼
- å°† eval_max_steps æ”¹ä¸º eval_interval ä»¥æ›´å‡†ç¡®æè¿°åŠŸèƒ½
- æ›´æ–°ç‰¹æ®Šæ ‡è®°æ ¼å¼ä¸º <|SBOS|> å’Œ <|SEOS|>
- è°ƒæ•´ vocab_size å’Œå¹¶è¡Œé…ç½®å‚æ•°
- ä¸ºæ—¥å¿—é…ç½®æ·»åŠ æ³¨é‡Šè¯´æ˜

### TODO:
1. ä¼˜åŒ–è®­ç»ƒè„šæœ¬ï¼š
- æ·»åŠ  æ—©åœæ£€æŸ¥
- æ·»åŠ  EMAï¼Œå¹³æ»‘æ”¶æ•›è¿‡ç¨‹ï¼Œæå‡ç²¾åº¦
- æ„å»º metrics.pyï¼Œç»Ÿä¸€ç®¡ç†è®­ç»ƒæŒ‡æ ‡
- ç²¾åº¦ä¸è®­ç»ƒæ”¶æ•›çš„é—®é¢˜
  - ä½¿ç”¨ Label Smoothingï¼Œé¿å…è¿‡æ‹Ÿåˆå’Œæå‡æ³›åŒ–èƒ½åŠ›ï¼Œå»ºè®®æ”¯æŒå‚æ•°é…ç½®ã€‚
  - å¼•å…¥ Prompt Maskã€Position Shiftç­‰è®­ç»ƒæŠ€å·§
  - PPLè®¡ç®—å¯èƒ½ä¸å‡†ç¡®ï¼Œå½“å‰ evaluate() ä¸­ ppl = exp(avg_loss)ï¼Œä½† avg_loss æ˜¯å¹³å‡ token lossï¼Œè‹¥ loss mask æœªæ­£ç¡®å¤„ç†ï¼Œå¯èƒ½é€ æˆè¿‡å¤§åå·®ã€‚
- ä½¿ç”¨FSDPï¼Œå½“å‰æœ€å¤§æ”¯æŒ DP + DDPï¼Œæœªä½¿ç”¨ torch.distributed.fsdpï¼Œå¯¹äºå‡ åäº¿å‚æ•°ä»¥ä¸Šçš„å¤§æ¨¡å‹åœ¨å¤šèŠ‚ç‚¹ä¸‹ä¸å¤Ÿé«˜æ•ˆã€‚
2. å®Œå–„æ„å¤–ç»ˆæ­¢å¤„ç†
- ä¿®å¤æ„å¤–ç»ˆæ­¢åçˆ†å‡ºå¤§é‡é”™è¯¯çš„é—®é¢˜ï¼Œå½“è®­ç»ƒæ„å¤–ç»ˆæ­¢æ—¶ï¼Œä¼šè§¦å‘å¼‚å¸¸æ•è·ï¼Œä½†å¼‚å¸¸æ•è·åæœªæ¸…ç†ç¯å¢ƒï¼Œå¯¼è‡´å¤§é‡é”™è¯¯æ—¥å¿—è¾“å‡ºã€‚
```
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 315, in _worker_loop
    r = index_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/connection.py", line 256, in poll
    return self._poll(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 315, in _worker_loop
    r = index_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/connection.py", line 423, in _poll
    r = wait([self], timeout)
        ^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/connection.py", line 930, in wait
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/connection.py", line 256, in poll
    return self._poll(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/connection.py", line 423, in _poll
    r = wait([self], timeout)
        ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/utils/checkpoint.py", line 202, in _handler
    self.ckpt_mgr.save_sync(self.model, self.optimizer, self.scaler,
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/connection.py", line 930, in wait
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/utils/checkpoint.py", line 77, in save_sync
    state = self._collect_state(model, optimizer, scaler,
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/utils/checkpoint.py", line 107, in _collect_state
    "scaler_state": scaler.state_dict() if scaler else None,
                    ^^^^^^^^^^^^^^^^^^^
  File "/workspace/utils/checkpoint.py", line 202, in _handler
    self.ckpt_mgr.save_sync(self.model, self.optimizer, self.scaler,
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 622, in state_dict
    "scale": self.get_scale(),
             ^^^^^^^^^^^^^^^^
  File "/workspace/utils/checkpoint.py", line 77, in save_sync
    state = self._collect_state(model, optimizer, scaler,
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 550, in get_scale
    else cast(float, scale.item())
                     ^^^^^^^^^^^^
  File "/workspace/utils/checkpoint.py", line 107, in _collect_state
    "scaler_state": scaler.state_dict() if scaler else None,
                    ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 622, in state_dict
    "scale": self.get_scale(),
             ^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 550, in get_scale
    else cast(float, scale.item())
                     ^^^^^^^^^^^^
RuntimeError: CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

RuntimeError: CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 315, in _worker_loop
    r = index_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/connection.py", line 256, in poll
    return self._poll(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/connection.py", line 423, in _poll
    r = wait([self], timeout)
        ^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/connection.py", line 930, in wait
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/utils/checkpoint.py", line 202, in _handler
    self.ckpt_mgr.save_sync(self.model, self.optimizer, self.scaler,
  File "/workspace/utils/checkpoint.py", line 77, in save_sync
    state = self._collect_state(model, optimizer, scaler,
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/utils/checkpoint.py", line 107, in _collect_state
    "scaler_state": scaler.state_dict() if scaler else None,
                    ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 622, in state_dict
    "scale": self.get_scale(),
             ^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 550, in get_scale
    else cast(float, scale.item())
                     ^^^^^^^^^^^^
RuntimeError: CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 315, in _worker_loop
    r = index_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/connection.py", line 256, in poll
    return self._poll(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/connection.py", line 423, in _poll
    r = wait([self], timeout)
        ^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/multiprocessing/connection.py", line 930, in wait
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/utils/checkpoint.py", line 202, in _handler
    self.ckpt_mgr.save_sync(self.model, self.optimizer, self.scaler,
  File "/workspace/utils/checkpoint.py", line 77, in save_sync
    state = self._collect_state(model, optimizer, scaler,
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/utils/checkpoint.py", line 107, in _collect_state
    "scaler_state": scaler.state_dict() if scaler else None,
                    ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 622, in state_dict
    "scale": self.get_scale(),
             ^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 550, in get_scale
    else cast(float, scale.item())
                     ^^^^^^^^^^^^
RuntimeError: CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[2025-07-18 13:12:28] [WARNING] [ByteLogger] ğŸ’€ æ”¶åˆ° SIGINTï¼Œå†™å…¥å®Œæ•´æ£€æŸ¥ç‚¹ â€¦
[2025-07-18 13:12:28] [ERROR] [ByteLogger] è®­ç»ƒå¼‚å¸¸: DataLoader worker (pid 2124) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.
[2025-07-18 13:12:28] [INFO] [ByteLogger] ğŸ’€ å¼‚å¸¸é€€å‡ºï¼Œæ­£åœ¨ä¿å­˜æ£€æŸ¥ç‚¹â€¦
Traceback (most recent call last):
  File "/workspace/model_pretrain.py", line 685, in <module>
    train(args, logger)
  File "/workspace/model_pretrain.py", line 636, in train
    raise e
  File "/workspace/model_pretrain.py", line 597, in train
    train_epoch(
  File "/workspace/model_pretrain.py", line 397, in train_epoch
    scaler.scale(loss).backward()
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/utils/checkpoint.py", line 202, in _handler
    self.ckpt_mgr.save_sync(self.model, self.optimizer, self.scaler,
  File "/workspace/utils/checkpoint.py", line 77, in save_sync
    state = self._collect_state(model, optimizer, scaler,
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/utils/checkpoint.py", line 107, in _collect_state
    "scaler_state": scaler.state_dict() if scaler else None,
                    ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 622, in state_dict
    "scale": self.get_scale(),
             ^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/amp/grad_scaler.py", line 550, in get_scale
    else cast(float, scale.item())
                     ^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 2124) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.
```
3. è§£å†³ æœªæ£€æµ‹æ¢¯åº¦å¼‚å¸¸ï¼ˆNaNï¼‰é—®é¢˜ï¼Œè‹¥ loss = NaNã€grad = infï¼Œåº”ç«‹å³ä¸­æ­¢è®­ç»ƒä¿å­˜ checkpointï¼Œé¿å…æµªè´¹èµ„æºã€‚

### DEBUG
1. æ‰¾å‡ºtorch.utils.checkpointé—®é¢˜æ ¹æºå¹¶è¿›è¡Œä¿®å¤
```
/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
```

</details>

---

<details>
<summary>2025.7.19</summary>

### DONE
1. ç»™æ¯ä¸ªç»„ä»¶æ·»åŠ ä¸“å±æ ‡å¿—
2. å®Œå–„requirements.txt
3. ä¼˜åŒ–è®­ç»ƒè„šæœ¬ï¼Œæ·»åŠ å¼‚å¸¸è‡ªåŠ¨å¤„ç†
4. æµ‹è¯•è®­ç»ƒè„šæœ¬é€šè¿‡
- è§£å†³å­˜åœ¨äºå¤šå¤´è‡ªæ³¨æ„åŠ›å±‚ä¸­çš„torch.utils.checkpointé…ç½®use_reentrant=Falseé—®é¢˜
- ä¿®å¤æ„å¤–ç»ˆæ­¢åçˆ†å‡ºå¤§é‡é”™è¯¯çš„é—®é¢˜ï¼Œå½“è®­ç»ƒæ„å¤–ç»ˆæ­¢æ—¶ï¼Œä¼šè§¦å‘å¼‚å¸¸æ•è·ï¼Œä½†å¼‚å¸¸æ•è·åæœªæ¸…ç†ç¯å¢ƒï¼Œå¯¼è‡´å¤§é‡é”™è¯¯æ—¥å¿—è¾“å‡ºã€‚
5. æ–°å¢å¤šé˜¶æ®µè®­ç»ƒçš„tokenizerå®ç°
- æ”¯æŒæ•°å­¦è¡¨è¾¾å¼ã€ä»£ç å—å’ŒXMLç»“æ„çš„ç‰¹æ®Šå¤„ç†
- å¤šé˜¶æ®µæ¸è¿›å¼è¯æ±‡è¡¨è®­ç»ƒ
- å†…å­˜ä¼˜åŒ–çš„æ‰¹å¤„ç†ç”Ÿæˆå™¨
- å®Œæ•´çš„é…ç½®æ–‡ä»¶å’Œç‰¹æ®Štokenæ”¯æŒ
- å†…ç½®è¯„ä¼°åŠŸèƒ½éªŒè¯tokenizeræ•ˆæœ
6. æ·»åŠ ç¯å¢ƒè®¾ç½®è„šæœ¬å’Œå®‰è£…æ–‡æ¡£
- æ·»åŠ  Windows å’Œ Unix çš„ç¯å¢ƒè®¾ç½®è„šæœ¬ï¼Œç”¨äºè‡ªåŠ¨åŒ–å®‰è£…å’Œé…ç½®å¼€å‘ç¯å¢ƒ
- æ·»åŠ  INSTALL.md å’Œ CONTRIBUTING.md æ–‡æ¡£ï¼Œæä¾›è¯¦ç»†çš„å®‰è£…å’Œè´¡çŒ®æŒ‡å—
- æ·»åŠ  setup.py ç”¨äºç®¡ç†é¡¹ç›®ä¾èµ–å’Œå®‰è£…é…ç½®
- ç¯å¢ƒè®¾ç½®è„šæœ¬æ”¯æŒä»¥ä¸‹åŠŸèƒ½ï¼š
  - æ£€æŸ¥ç³»ç»Ÿä¾èµ–
  - åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
  - å®‰è£…é¡¹ç›®ä¾èµ–
  - éªŒè¯å®‰è£…
  - æ”¯æŒå¼€å‘ç¯å¢ƒå’Œ CUDA é€‰é¡¹
7. ä¼˜åŒ–ä½ç½®ç¼–ç 
- æ·»åŠ max_seq_lenå‚æ•°ï¼Œæ”¯æŒé¢„è®¡ç®—å¹¶ç¼“å­˜æœ€å¤§é•¿åº¦çš„ä½ç½®ç¼–ç 
- ä¼˜åŒ–_get_cos_sin_scaleæ–¹æ³•ï¼Œæ”¯æŒé€šè¿‡offsetå‚æ•°è·å–æŒ‡å®šçª—å£çš„ç¼–ç åˆ‡ç‰‡
8. ä¼˜åŒ–Attentionï¼Œæ·»åŠ repeat_kvæ–¹æ³•å®ç°Grouped-Query Attentionç”¨äºé‡å¤Key/Valueå¼ é‡ä»¥åŒ¹é…Queryçš„å¤´æ•°
9. é‡æ„é—¨æ§å¤šå±‚æ„ŸçŸ¥æœºæ¨¡å—å¹¶æ·»åŠ æ®‹å·®è¿æ¥
- åˆå¹¶w1å’Œw3ä¸ºå…±äº«å‚æ•°çš„w13çº¿æ€§å±‚
- ä½¿ç”¨GEGLUé—¨æ§ç»“æ„æ›¿ä»£åŸæœ‰å®ç°
- æ·»åŠ ByteRMSNormå½’ä¸€åŒ–å±‚
- å¼•å…¥æ®‹å·®è¿æ¥æå‡æ¢¯åº¦æµåŠ¨
10. æ„å»ºåŸºç¡€çš„MoEå±‚ï¼Œä½†æ˜¯ç»“æ„é€»è¾‘è¿˜ä¸å®Œå–„æ— æ³•åº”ç”¨ï¼Œéœ€è¦ä¼˜åŒ–
11. æ„å»ºåŸºç¡€çš„MeMoryè®°å¿†æœºåˆ¶ï¼Œæ”¯æŒä»¥ä¸‹åŠŸèƒ½ï¼š
- update(layer_idx, new_hidden)
  - æ›´æ–°æŒ‡å®šå±‚çš„ memoryã€‚
  - æ”¯æŒ detach()ï¼Œé¿å…æ¢¯åº¦å›ä¼ æ±¡æŸ“ï¼›
  - è‹¥åŸæœ‰è®°å¿†ä¸ä¸ºç©ºï¼Œåˆ™æ‹¼æ¥å½“å‰ new_hidden å¹¶æˆªæ–­è‡³ mem_lenï¼›
  - è‡ªåŠ¨è¿›è¡Œè®¾å¤‡åŒ¹é…ï¼ˆå¦‚åˆ‡ GPUï¼‰ã€‚
- update_all(new_hiddens)
  - æ‰¹é‡æ›´æ–°æ‰€æœ‰å±‚çš„è®°å¿†ï¼ˆä¾‹å¦‚æ¯æ¬¡ forward åæ›´æ–°ï¼‰ã€‚
  - è¦æ±‚ä¼ å…¥çš„åˆ—è¡¨é•¿åº¦ç­‰äº n_layersï¼›
  - å†…éƒ¨è°ƒç”¨ update å‡½æ•°ã€‚
- get(layer_idx),è¿”å›æŒ‡å®šå±‚çš„è®°å¿†ï¼Œç”¨äºå½“å‰æ¨ç†æ‹¼æ¥ã€‚
- clear(),æ¸…é™¤æ‰€æœ‰å±‚çš„è®°å¿†ï¼ˆå¯ç”¨äºæ¯æ®µä¸Šä¸‹æ–‡/ä»»åŠ¡ä¹‹é—´æ¸…é›¶ï¼‰ã€‚
- to(device),å°†å½“å‰ç¼“å­˜è¿ç§»è‡³æŒ‡å®šè®¾å¤‡ï¼ˆé€šå¸¸åœ¨æ¨¡å‹è¿ç§»æ—¶åŒæ­¥è¿ç§»ï¼‰ã€‚
- memory_size(),è¿”å›å„å±‚å½“å‰ä¿ç•™çš„è®°å¿†é•¿åº¦ï¼ˆtoken æ•°ï¼‰ï¼Œæœ‰åŠ©äºè°ƒè¯•ã€‚
- __repr__(),æ¸…æ™°å±•ç¤ºå½“å‰å†…å­˜ä½¿ç”¨çŠ¶æ€ï¼Œæ–¹ä¾¿æ—¥å¿—è¾“å‡ºã€‚

### TODO
1. MoEå±‚ä¼˜åŒ–ï¼š
- åˆ†å¸ƒå¼MoEï¼Œæ¥å…¥ DeepSpeed-MoE æˆ– FSDP çš„ MoE å®ç°æ¨¡å—
- è·¯ç”±å™¨é‡å‚æ•°ä¼˜åŒ–ï¼Œä½¿ç”¨ GShard-style noisy-topk æˆ– Gumbel Softmax æé«˜æ¢ç´¢èƒ½åŠ›
- é«˜æ•ˆä¸“å®¶å…±äº«ï¼Œå¤šä¸ª MoE å±‚å¤ç”¨å…±äº«ä¸“å®¶æ± ï¼ˆå¦‚ M6ã€GLaMï¼‰ï¼Œå¯ç”¨ä¸“å®¶æ± ç»Ÿä¸€è°ƒåº¦
- æé«˜ token åˆ†æ´¾å’Œæ‰§è¡Œæ•ˆç‡	,æ›¿ä»£é€ä¸“å®¶æ”¶é›†æ–¹å¼ï¼Œè½¬å‘åŸºäºç¨€ç–è¡¨ç¤ºçš„å¹¶è¡Œå¤„ç†
- å‡å°‘å†…å­˜æµªè´¹,ç”¨ç¨€ç–å¼ é‡æˆ–ç¨€ç–è·¯ç”±ç»“æ„æ›¿ä»£ç¨ å¯† dispatch_mask
- å¢å¼ºé²æ£’æ€§,å¯¹ token æº¢å‡ºéƒ¨åˆ†å¼•å…¥â€œæ®‹å·®è·¯å¾„â€æˆ–å†è·¯ç”±æœºåˆ¶
- æ”¹è¿›è´Ÿè½½å‡è¡¡ Loss,å¼•å…¥ softmax entropyã€expected load KL loss ç­‰æ›´åˆç†çš„çº¦æŸ
- å¢å¼ºæ¨¡å—æ¸…æ™°åº¦å’Œå¯ç»´æŠ¤æ€§,æ‹†è§£åŠŸèƒ½å‡½æ•°ã€æ¸…æ™°æ³¨é‡Šã€å‘½åæ ‡å‡†åŒ–
- åŠ¨æ€ä¸“å®¶æ¿€æ´»æ•° k,è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªåŠ¨è°ƒæ•´ kï¼Œæ›´æ™ºèƒ½åŒ–è°ƒåº¦
- æ··åˆå®¹é‡è°ƒåº¦ç­–ç•¥,é«˜ä¼˜å…ˆ token åˆ†é…æ›´å¤šå®¹é‡
- æ¨¡å—åŒ–è§£è€¦,åˆ†ç¦» Gate, Router, Expert æ›´ä¾¿äºæ›¿æ¢
2. å°è¯•åµŒå…¥MoEå±‚ä¼˜åŒ–æ¨¡å‹
3. MeMoryæœºåˆ¶ä¼˜åŒ–ï¼š
- æ”¯æŒæ»‘åŠ¨çª—å£æ›´æ–°ï¼Œè®¾å®šçª—å£æ»‘åŠ¨çš„æ¯”ä¾‹ï¼Œå®ç°æ›´åŠ å¹³æ»‘çš„è®°å¿†æ›´æ›¿
- æ··åˆKVCacheï¼Œå°†KVç¼“å­˜ä¸hidden memoryç»Ÿä¸€ç®¡ç†ï¼Œä¸ºAttentionæœåŠ¡
- æŒä¹…åŒ–ä¿å­˜ï¼Œæä¾›save()ã€load()ï¼Œæ”¯æŒä¸­æ–­æ¢å¤

</details>

---

<details>
<summary>2025.7.20</summary>

### DONE
1. æ„å»ºMoERouterè·¯ç”±ç³»ç»Ÿ
- ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„é—¨æ§æœºåˆ¶ï¼ˆContext-Aware Gatingï¼‰ -> å¯æ”¯æŒé•¿åºåˆ—ã€å¤šè¯­è¨€ã€å¤§æ¨¡å‹è°ƒåº¦åœºæ™¯ï¼Œå¯¹ç¨€ç–è¡¨ç¤ºå»ºæ¨¡èƒ½åŠ›å¼ºã€‚
  - å¼•å…¥ä½ç½®ç¼–ç  + å†å²çŠ¶æ€ + å½“å‰è¯­ä¹‰ç‰¹å¾å½¢æˆè”åˆä¸Šä¸‹æ–‡è¡¨ç¤ºï¼ˆcontext_featï¼‰ã€‚
  - é—¨æ§ç½‘ç»œ (gate_mlp) è¾“å…¥ä¸º [x, context_feat]ï¼Œå¯é€‚åº”å½“å‰tokenä¸ä¸Šä¸‹æ–‡çš„å¾®å¦™å˜åŒ–ã€‚
  - RMSNorm ä¸ dropout æå‡æ¨¡å‹ç¨³å®šæ€§ä¸æ³›åŒ–èƒ½åŠ›ã€‚
- æ¸©åº¦åŠ¨æ€è°ƒæ•´ä¸ä¸“å®¶ä¼˜å…ˆçº§ -> å®ç°å†·çƒ­ä¸“å®¶åŠ¨æ€æ¿€æ´»ã€æ”¶æ•›æ›´å¿«ã€è·¯ç”±æ›´ç¨³å®šã€token åˆ†å¸ƒæ›´å‡è¡¡ã€‚
  - ä½¿ç”¨ self.temperature æ ¹æ®ä¸“å®¶è´Ÿè½½å·®å¼‚åŠ¨æ€è°ƒæ•´ softmax æ¸©åº¦ï¼Œæ§åˆ¶ä¸“å®¶é€‰æ‹©çš„åˆ†å¸ƒç†µã€‚
  - ä¸“å®¶ä¼˜å…ˆçº§é€šè¿‡ self.expert_priority å’Œ self.expert_cold_priority åŠ¨æ€æ›´æ–°ï¼Œå¯¹ä¸æ´»è·ƒä¸“å®¶æä¾›å†·å¯åŠ¨æ”¯æŒã€‚
- åŠ¨æ€å®¹é‡è°ƒæ§æœºåˆ¶ -> è§£å†³ token åˆ†å¸ƒæä¸å‡è¡¡æ—¶çš„å®¹é‡ç“¶é¢ˆé—®é¢˜ï¼Œæ˜¯å¤§è§„æ¨¡ MoE æ¨¡å‹éƒ¨ç½²çš„å…³é”®ç»„ä»¶ã€‚
  - ä½¿ç”¨ä¸“å®¶åˆ©ç”¨ç‡ (expert_utilization) è°ƒæ•´æ¯è½® capacityï¼Œé˜²æ­¢éƒ¨åˆ†ä¸“å®¶é•¿æœŸé¥±å’Œæˆ–é—²ç½®ã€‚
  - å¯è®¾ç½®æœ€å¤§/æœ€å°å®¹é‡ä¸Šä¸‹é™ï¼Œå…¼é¡¾å¼¹æ€§ä¸ç¨³å®šæ€§ã€‚
- é«˜æ•ˆçš„å‘é‡åŒ–ä¸“å®¶åˆ†å‘è°ƒåº¦ -> å®Œå…¨å‘é‡åŒ–å®ç°ï¼Œæ€§èƒ½ä¼˜äº for-loop è°ƒåº¦ï¼›é€‚ç”¨äº TP/SP å¹¶è¡Œç¯å¢ƒä¸‹çš„è°ƒåº¦è®¡åˆ’ç”Ÿæˆã€‚
  - _vectorized_dispatch åŸºäº torch_scatter + top-k åˆ†å‘æƒé‡æ„å»ºä¸“å®¶-æ ·æœ¬æ˜ å°„è¡¨ã€‚
  - token ä¸»å¯¼åˆ†å‘ï¼ˆç”± gate è¾“å‡ºæ§åˆ¶ï¼‰ï¼Œä¸“å®¶ä¸»å¯¼ç­›é€‰ï¼ˆåŸºäºåˆ†é…ä¼˜å…ˆçº§ä¸å®¹é‡é™åˆ¶ï¼‰ã€‚
  - åˆ†é…é€»è¾‘æ˜ç¡®ï¼šå¯ç”¨ä¸“å®¶ä¼˜å…ˆ + æƒé‡è¶Šå¤§ä¼˜å…ˆã€‚
- æº¢å‡ºå¤„ç†æœºåˆ¶ï¼ˆOverflow Handlingï¼‰ -> é¿å… token ä¸¢å¤±ï¼Œä¿éšœæ¨¡å‹é²æ£’æ€§ï¼Œæé«˜æ¨¡å‹è®­ç»ƒç¨³å®šæ€§ã€‚
  - æº¢å‡ºtoken é‡‡ç”¨ å¤‡é€‰ä¸“å®¶æœºåˆ¶ï¼ˆé top-k ä¸­åˆ†æ•°æœ€é«˜çš„ï¼‰ã€å†·å¯åŠ¨ä¸“å®¶è·¯ç”±ã€å†å²ä¸“å®¶ç²˜æ€§ fallback å’Œæœ€ç»ˆ éšæœº fallbackã€‚
  - fallback å€¾å‘äºé€‰æ‹©è´Ÿè½½è½» + é•¿æœŸæœªæ´»è·ƒ + å­¦ä¹ æƒé‡é«˜çš„ä¸“å®¶ã€‚
- å¤šç›®æ ‡è´Ÿè½½å‡è¡¡æŸå¤±ï¼ˆAux Lossï¼‰ -> ä¿è¯è·¯ç”±ç¨³å®šä¸ä¸“å®¶å‡åŒ€è´Ÿè½½ï¼Œæå‡è®­ç»ƒæ•ˆç‡å’Œä¸“å®¶æ³›åŒ–èƒ½åŠ›ã€‚
  - é€šè¿‡ KLã€MSE å’Œä¸“å®¶ load variance å®ç°è·¯ç”±ç†µçº¦æŸï¼Œæå‡åˆ†å¸ƒå‡åŒ€æ€§ã€‚
  - å¼•å…¥ token entropy æƒé‡æœºåˆ¶ï¼Œé«˜ä¸ç¡®å®šæ€§ token è¢«æ›´ç²¾ç»†å¤„ç†ã€‚
- ä¸“å®¶çŠ¶æ€æ›´æ–°ä¸è‡ªé€‚åº”å­¦ä¹  -> å®ç°ä¸“å®¶ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼Œæ”¯æŒåœ¨çº¿ä¸“å®¶å‰”é™¤/æ›¿æ¢ã€å†·çƒ­ä¸“å®¶åˆ‡æ¢ç­‰æœºåˆ¶ã€‚
  - ç»´æŠ¤ä¸“å®¶åˆ†é…çŠ¶æ€ï¼ˆexpert_load, utilization, priorityï¼‰å¹¶é€šè¿‡ EMA æ›´æ–°ã€‚
  - ç»Ÿè®¡ä¿¡æ¯æ”¯æŒåŠ¨æ€è°ƒåº¦å†³ç­–ä¸è®­ç»ƒæŒ‡æ ‡ç›‘æ§ã€‚
2. ä¸€å¥MoERouteré‡æ„MoEå±‚
- ä¸“å®¶å¹¶è¡Œï¼ˆExpert Parallelismï¼‰æ”¯æŒï¼šè®¾è®¡ä¸­æ˜ç¡®åŒºåˆ†äº†num_expertsï¼ˆå…¨å±€ä¸“å®¶æ•°ï¼‰å’Œnum_local_expertsï¼ˆå½“å‰è®¾å¤‡ä¸Šçš„ä¸“å®¶æ•°ï¼‰ï¼Œå¹¶ä¸”é€šè¿‡diståˆ†å¸ƒå¼é€šä¿¡ç®¡ç†ä¸“å®¶å¹¶è¡Œã€‚
- åŠ¨æ€å®¹é‡ç®¡ç†ï¼šé€šè¿‡router_configä¸­max_capacityå‚æ•°ä»¥åŠç¼“å†²åŒºexpert_inputså’Œexpert_outputsçš„åŠ¨æ€åˆ†é…ï¼Œå¯¹ä¸“å®¶è¾“å…¥å®¹é‡çš„æ§åˆ¶ï¼Œé¿å…äº†é™æ€å›ºå®šå®¹é‡å¯¼è‡´çš„å†…å­˜æµªè´¹ã€‚
- å®¹é”™è·¯ç”±æœºåˆ¶ï¼šä½¿ç”¨fallback_expertæ¥å¤„ç†â€œæº¢å‡ºtokenâ€ï¼Œé˜²æ­¢å› ä¸“å®¶å®¹é‡é™åˆ¶å¯¼è‡´tokenä¸¢å¤±ï¼Œå¢å¼ºé²æ£’æ€§ã€‚åŒæ—¶æä¾›dropoutæœºåˆ¶ï¼Œé¿å…è¿‡æ‹Ÿåˆã€‚
- é›¶æµªè´¹å†…å­˜ç®¡ç†ï¼šé¢„æ³¨å†Œç¼“å†²åŒºé¿å…åŠ¨æ€å†…å­˜åˆ†é…ï¼Œå‡å°‘æ˜¾å­˜ç¢ç‰‡å’Œé¢‘ç¹åˆ†é…å¼€é”€ï¼Œåˆ©äºé«˜æ•ˆè®­ç»ƒã€‚
- æ„å»ºä¸°å¯Œæ€§èƒ½ç›‘æ§æŒ‡æ ‡ï¼šåŒ…æ‹¬ä¸“å®¶åˆ©ç”¨ç‡ã€è´Ÿè½½ä¸å‡è¡¡åº¦ã€æº¢å‡ºç‡ç­‰ï¼Œæ–¹ä¾¿å®æ—¶ç›‘æ§MoEå±‚è¿è¡ŒçŠ¶å†µã€‚
- åŠ¨æ€ä¸“å®¶è´Ÿè½½å‡è¡¡ï¼ˆsplit/mergeï¼‰ç­–ç•¥ï¼šè®¾è®¡äº†æ ¹æ®åˆ©ç”¨ç‡åŠ¨æ€åˆ†è£‚è¿‡è½½ä¸“å®¶ã€åˆå¹¶ä½è½½ä¸“å®¶çš„æœºåˆ¶ï¼Œæœ‰åˆ©äºè®­ç»ƒæœŸé—´ä¸“å®¶èµ„æºè‡ªé€‚åº”è°ƒæ•´ï¼Œæå‡æ¨¡å‹æ•ˆç‡ã€‚
- è®¾è®¡åˆç†ä¸“å®¶æ¨¡å—ï¼šä¸“å®¶å†…éƒ¨ä½¿ç”¨å¸¦é—¨æ§çš„GLUç»“æ„ï¼ˆæ¿€æ´»+é—¨æ§ä¹˜ç§¯ï¼‰åŠå½’ä¸€åŒ–ï¼Œç¬¦åˆå½“å‰MoEä¸“å®¶çš„ä¸»æµè®¾è®¡ï¼Œè®¡ç®—æ•ˆç‡å’Œè¡¨è¾¾èƒ½åŠ›å…¼é¡¾ã€‚
3. Memoryæœºåˆ¶ä¼˜åŒ–ï¼š
- åˆ†å±‚è®°å¿†æ§åˆ¶ï¼šåº•å±‚å¯ä¿ç•™æ›´é•¿å†å²ï¼Œé«˜å±‚å¯å‡å°‘è®¡ç®—
- æ™ºèƒ½batchå¤„ç†ï¼šæ”¯æŒbatchå°ºå¯¸å˜åŒ–æ—¶çš„è‡ªåŠ¨å¹¿æ’­/è£å‰ª
- è®°å¿†èåˆï¼šæ–°æ—§è®°å¿†åŠ æƒèåˆä¿ç•™å…³é”®ä¿¡æ¯
- ç­–ç•¥é…ç½®ï¼šæä¾›strict/select/repeatä¸‰ç§å°ºå¯¸é€‚é…ç­–ç•¥
4. æ„å»ºç›¸å…³æµ‹è¯•ä»£ç å¹¶ä¿®å¤bug
- æ„å»ºMemoryæµ‹è¯•ä»£ç å¹¶æµ‹è¯•é€šè¿‡ï¼Œä¿®å¤äº†ç›¸å…³BUG
- æ„å»ºMoERouteræµ‹è¯•ä»£ç å¹¶æµ‹è¯•é€šè¿‡ï¼Œä¿®å¤äº†ç›¸å…³BUG

### TODO
1. MoEå±‚ä¼˜åŒ–ï¼š
- æ„å»ºMoEå±‚é¢„çƒ­æœºåˆ¶
2. è®­ç»ƒè„šæœ¬ä¸­åŠ å…¥
- update_cold_priority()ï¼Œç”¨äºæ›´æ–°å†·é—¨ä¸“å®¶ä¼˜å…ˆçº§
```python
@torch.no_grad()
def update_cold_priority(self):
    # åˆ©ç”¨å½“å‰ä¸“å®¶åˆ©ç”¨ç‡ï¼Œä½åˆ©ç”¨ç‡ä¸“å®¶å†·å¯åŠ¨ä¼˜å…ˆçº§æå‡
    utilization = self.expert_utilization.clamp(0, 1)
    cold_priority = 1.0 + (1.0 - utilization)  # ä½åˆ©ç”¨ç‡åŠ æˆèŒƒå›´[1,2]
    self.expert_cold_priority.copy_(cold_priority)
```
3. æ„å»ºtest_MoERouter.pyæµ‹è¯•ä»£ç ï¼Œå¹¶ä¿®å¤ç›¸å…³BUG
4. æ„å»ºtest_MoE.pyæµ‹è¯•ä»£ç ï¼Œå¹¶ä¿®å¤ç›¸å…³BUG
5. å°è¯•åµŒå…¥MoEå±‚ä¼˜åŒ–æ¨¡å‹
6. MoERouterè¿˜å­˜åœ¨å¦‚ä¸‹é—®é¢˜å¾…è§£å†³ï¼š
- é—®é¢˜ 1ï¼šä¸“å®¶å†·å¯åŠ¨æƒé‡çš„åˆå§‹åŒ–è¿‡äºç»Ÿä¸€ï¼Œself.expert_cold_priority é»˜è®¤å…¨ä¸º 1ï¼Œç¼ºä¹åŸºäºå†å²ç»Ÿè®¡çš„åˆå§‹åŒ–ç­–ç•¥ã€‚
  - å»ºè®®ï¼šå¯å¼•å…¥å†·å¯åŠ¨å†å²æ—¶é—´æˆ³æˆ–å†·å´æ—¶é—´çª—å£ï¼ŒåŠ¨æ€æ›´æ–° [1.0, 2.0] åˆ†å¸ƒã€‚
- é—®é¢˜ 2ï¼šfallback è¿‡ç¨‹å­˜åœ¨å†²çªé£é™©ï¼Œåœ¨ _handle_overflow_fallback ä¸­ï¼Œå¤šä¸ª token å¯èƒ½äº‰ç”¨åŒä¸€ä¸“å®¶ï¼Œå°¤å…¶åœ¨ batch å¤§æ—¶æœªå®Œå…¨å¹¶å‘å®‰å…¨ã€‚
  - å»ºè®®ï¼šå¯å¼•å…¥ dispatch_bitmap æˆ–åˆ©ç”¨ index_put_ + åŸå­è®¡æ•°æ–¹æ¡ˆæ›´å®‰å…¨æ›´æ–°ã€‚
- é—®é¢˜ 4ï¼šä¸“å®¶åˆ†é…ç­–ç•¥ç¼ºä¹åˆ†å¸ƒå¼æ„ŸçŸ¥ï¼Œå½“å‰æ‰€æœ‰ä¸“å®¶è°ƒåº¦é€»è¾‘åŸºäºå•èŠ‚ç‚¹ä¿¡æ¯ï¼Œä¸è€ƒè™‘è·¨ GPU / TP experts çš„åˆ†å¸ƒã€‚
  - å»ºè®®ï¼šå¼•å…¥è·¨è®¾å¤‡ expert_rankï¼Œæ„å»º local_vs_global_expert_maskï¼Œå®ç°è·¨èŠ‚ç‚¹è´Ÿè½½å‡è¡¡ã€‚
- é—®é¢˜ 5ï¼šè°ƒåº¦ä¿¡æ¯æœªæ˜¾å¼æ”¯æŒå¤šç²’åº¦ token åˆ†é…ï¼Œå½“å‰æ‰€æœ‰åˆ†é…åŸºäº flat tokenï¼Œå¦‚æœè¾“å…¥æœ‰ padding/attention maskï¼Œåˆ™å¯èƒ½é”™è¯¯åˆ†é…ã€‚
  - å»ºè®®ï¼šå¼•å…¥ token_mask æœºåˆ¶ï¼Œç²¾ç¡®æ§åˆ¶æœ‰æ•ˆ tokenã€‚
- é—®é¢˜ 6ï¼šè´Ÿè½½ç»Ÿè®¡çŠ¶æ€æœªæŒä¹…åŒ–/å­˜ç›˜ï¼Œexpert_priority, utilization ç­‰çŠ¶æ€å‚æ•°åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å˜åŒ–å¤§ï¼Œä½†æœªæŒä¹…åŒ–æˆ–å¤ç”¨ã€‚
  - å»ºè®®ï¼šåŠ æŒä¹…åŒ–æ¥å£ï¼ˆå¦‚save_state_dict / load_state_dictï¼‰ï¼Œæ”¯æŒçƒ­é‡å¯ã€‚

</details>

---

<details>
<summary>2025.7.21</summary>

### DONE
1. å°†è®¸å¯è¯ä»MITæ›´æ”¹ä¸ºCC BY-NC 4.0,æ›´æ–°è®¸å¯è¯æ–‡ä»¶ä»¥ä½¿ç”¨CC BY-NC 4.0åè®®ï¼Œæ·»åŠ äº†éå•†ä¸šä½¿ç”¨é™åˆ¶å’Œç½²åè¦æ±‚
2. ä¼˜åŒ–MoERouterè·¯ç”±ç³»ç»Ÿï¼Œ å¢å¼ºè·¯ç”±å™¨çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›å’Œå®¹é”™æœºåˆ¶
- æ–°å¢max_positionså‚æ•°æ§åˆ¶ä½ç½®ç¼–ç èŒƒå›´
- é‡æ„é—¨æ§ç½‘ç»œè¾“å…¥ç»´åº¦ï¼ŒåŠ å…¥ä½ç½®å’Œå†å²ä¿¡æ¯
- æ”¹è¿›æº¢å‡ºå¤„ç†é€»è¾‘ï¼Œå¢åŠ åŠ¨æ€å¤‡é€‰ä¸“å®¶é€‰æ‹©å’Œç²˜æ€§å›é€€æœºåˆ¶
- ä¼˜åŒ–ä¸“å®¶è´Ÿè½½ç»Ÿè®¡ç²¾åº¦ï¼Œä½¿ç”¨float32ç±»å‹
- ä¿®å¤æ½œåœ¨çš„ç©ºæº¢å‡ºå¤„ç†è¾¹ç•Œæƒ…å†µ
3. é‡æ„MoELayerï¼Œä½¿ç”¨ByteMoERouteræ„é€ åŸºç¡€ByteMoELayerï¼Œæš‚ä¸æ”¯æŒDDP

### TODO
1. ByteMoELayerå‡çº§ä¼˜åŒ–ï¼ŒæŒ‰ç…§DeepSeed-MoEé£æ ¼æ„é€ åˆ†å¸ƒå¼ByteMoELayerï¼Œä»å•ä¸€çš„localæ˜¯å…ˆåˆ°å¤šå¡åˆ†å¸ƒå¼
2. ä½¿ç”¨pytestæ„å»ºByteMoELayerï¼Œå¹¶ä¿®å¤ç›¸å…³BUG

</details>

---

<details>
<summary>2025.7.22</summary>

### DONE
1. ä¿®å¤XPosä½ç½®ç¼–ç ä¸­çš„bug,å°†_get_cos_sin_scaleå‡½æ•°ä¸­çš„ä»RotaryCacheåˆå§‹åŒ–å‚æ•°seq_lenï¼Œä»self.max_seq_lenä¿®æ”¹ä¸ºseq_len
```
Traceback (most recent call last):
  File "/workspace/model_pretrain.py", line 686, in <module>
    train(args, logger)
  File "/workspace/model_pretrain.py", line 636, in train
    raise e
  File "/workspace/model_pretrain.py", line 597, in train
    train_epoch(
  File "/workspace/model_pretrain.py", line 397, in train_epoch
    scaler.scale(loss).backward()
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1124, in unpack_hook
    frame.recompute_fn(*args)
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1518, in recompute_fn
    fn(*args, **kwargs)
  File "/workspace/model/Model.py", line 215, in custom_forward
    return layer(*inputs)
           ^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/model/DecoderLayer.py", line 102, in forward
    attn_out = self.self_attn(self.norm_attn(x), additive_mask)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/model/Attention.py", line 375, in forward
    q = q * cos + self.rotary._rotate_half(q) * sin
        ~~^~~~~
RuntimeError: The size of tensor a (2047) must match the size of tensor b (0) at non-singleton dimension 1
```
2. ä¿®å¤model_pretrain.pyä¸­çš„è®¾å¤‡ä¸ä¸€è‡´é—®é¢˜
**å…³é”®è¯­å¥**
```python
gpu_mem       = torch.cuda.memory_allocated(args.device) if torch.cuda.is_available() else 0
```
**æŠ¥é”™**
```
Traceback (most recent call last):
  File "/workspace/model_pretrain.py", line 686, in <module>
    train(args, logger)
  File "/workspace/model_pretrain.py", line 636, in train
    raise e
  File "/workspace/model_pretrain.py", line 597, in train
    train_epoch(
  File "/workspace/model_pretrain.py", line 429, in train_epoch
    gpu_mem       = torch.cuda.memory_allocated(args.device) if torch.cuda.is_available() else 0
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/cuda/memory.py", line 537, in memory_allocated
    return memory_stats(device=device).get("allocated_bytes.all.current", 0)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/cuda/memory.py", line 323, in memory_stats
    stats = memory_stats_as_nested_dict(device=device)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/cuda/memory.py", line 334, in memory_stats_as_nested_dict
    device = _get_device_index(device, optional=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/cuda/_utils.py", line 34, in _get_device_index
    raise ValueError(f"Expected a cuda device, but got: {device}")
ValueError: Expected a cuda device, but got: cpu
```
**åŸå› **
torch.cuda.memory_allocated() åªèƒ½æ¥å— CUDA è®¾å¤‡ï¼ˆå¦‚ "cuda:0"ï¼‰ï¼Œè€Œåœ¨è®­ç»ƒè„šæœ¬ä¸­å¯èƒ½ä¼ å…¥çš„æ˜¯ "cpu"ï¼Œè¿™åœ¨ CPU-only ç¯å¢ƒä¸‹æˆ–åœ¨é€»è¾‘ä¸­æ˜¾å¼ä½¿ç”¨ CPU è®¾å¤‡æ—¶ä¼šå‡ºé”™ã€‚
**ä¿®å¤**
```python
gpu_mem       = torch.cuda.memory_allocated(args.device) if args.device=="cuda" and torch.cuda.is_available() else 0
```
3. XPosä½ç½®ç¼–ç ï¼Œç§»é™¤XPosRotaryEmbeddingä¸­çš„offsetå‚æ•°ï¼Œæ”¹ä¸ºç›´æ¥æ ¹æ®å½“å‰åºåˆ—é•¿åº¦ç”Ÿæˆcos/sin/scaleç®€åŒ–_get_cos_sin_scaleå’Œ_compute_xpos_scaleæ–¹æ³•çš„å®ç°ï¼Œä¸å†éœ€è¦offsetåˆ‡ç‰‡æ“ä½œã€‚

### TODO
åœ¨æœ‰é™çš„èµ„æºæƒ…å†µä¸‹ï¼Œå°è¯•è°ƒè¯•è®­ç»ƒè„šæœ¬ï¼Œä¿®å¤æŠ¥é”™

### DEBUG
1. å¯ç”¨grad_checkpointï¼Œä¼˜åŒ–è®­ç»ƒé€Ÿåº¦æŠ¥é”™
```
raceback (most recent call last):
  File "/workspace/model_pretrain.py", line 686, in <module>
    train(args, logger)
  File "/workspace/model_pretrain.py", line 636, in train
    raise e
  File "/workspace/model_pretrain.py", line 597, in train
    train_epoch(
  File "/workspace/model_pretrain.py", line 397, in train_epoch
    scaler.scale(loss).backward()
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 1128, in unpack_hook
    frame.check_recomputed_tensors_match(gid)
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/utils/checkpoint.py", line 902, in check_recomputed_tensors_match
    raise CheckpointError(
torch.utils.checkpoint.CheckpointError: torch.utils.checkpoint: Recomputed values for the following tensors have different metadata than during the forward pass.
tensor at position 14:
saved metadata: {'shape': torch.Size([2047, 1]), 'dtype': torch.float32, 'device': device(type='cuda', index=0)}
recomputed metadata: {'shape': torch.Size([4094, 1]), 'dtype': torch.float32, 'device': device(type='cuda', index=0)}
tensor at position 15:
saved metadata: {'shape': torch.Size([2047, 24]), 'dtype': torch.float32, 'device': device(type='cuda', index=0)}
recomputed metadata: {'shape': torch.Size([4094, 24]), 'dtype': torch.float32, 'device': device(type='cuda', index=0)}
tensor at position 24:
saved metadata: {'shape': torch.Size([96, 48, 2047]), 'dtype': torch.bfloat16, 'device': device(type='cuda', index=0)}
recomputed metadata: {'shape': torch.Size([96, 48, 2048]), 'dtype': torch.bfloat16, 'device': device(type='cuda', index=0)}
tensor at position 26:
saved metadata: {'shape': torch.Size([6, 16, 2047, 2047]), 'dtype': torch.float32, 'device': device(type='cuda', index=0)}
recomputed metadata: {'shape': torch.Size([6, 16, 2047, 2048]), 'dtype': torch.float32, 'device': device(type='cuda', index=0)}
tensor at position 27:
saved metadata: {'shape': torch.Size([6, 16, 2047, 2047]), 'dtype': torch.bool, 'device': device(type='cuda', index=0)}
recomputed metadata: {'shape': torch.Size([6, 16, 2047, 2048]), 'dtype': torch.bool, 'device': device(type='cuda', index=0)}
tensor at position 28:
saved metadata: {'shape': torch.Size([96, 2047, 48]), 'dtype': torch.bfloat16, 'device': device(type='cuda', index=0)}
recomputed metadata: {'shape': torch.Size([96, 2048, 48]), 'dtype': torch.bfloat16, 'device': device(type='cuda', index=0)}
```
2. å¯ç”¨torch_compileæŠ¥é”™
```
ALLOW_TF32=True, BLOCK_K=64, BLOCK_M=64, BLOCK_N=128, EVEN_K=True, GROUP_M=8, num_stages=3, num_warps=4
  triton_mm_1817 15.9234 ms 69.1% ACC_TYPE='tl.float32', ALLOW_TF32=True, BLOCK_K=16, BLOCK_M=64, BLOCK_N=64, EVEN_K=True, GROUP_M=8, num_stages=2, num_warps=4
SingleProcess AUTOTUNE benchmarking takes 10.1738 seconds and 0.0001 seconds precompiling for 20 choices
skipping cudagraphs due to skipping cudagraphs due to cpu device (primals_9). Found from : 
   File "/workspace/model/Model.py", line 223, in forward
    hidden_states = layer(hidden_states, additive_mask)
  File "/workspace/model/DecoderLayer.py", line 102, in forward
    attn_out = self.self_attn(self.norm_attn(x), additive_mask)
  File "/workspace/model/Attention.py", line 414, in forward
    scores = ( q.to(compute_dtype) @ k_cat.to(compute_dtype).transpose(-1,-2) ) * self.scale.to(compute_dtype)  # [B,H,T,Tk]
```
```
Traceback (most recent call last):
  File "/workspace/model_pretrain.py", line 686, in <module>
    train(args, logger)
  File "/workspace/model_pretrain.py", line 636, in train
    raise e
  File "/workspace/model_pretrain.py", line 597, in train
    train_epoch(
  File "/workspace/model_pretrain.py", line 392, in train_epoch
    outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 655, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/model/Model.py", line 166, in forward
    def forward(
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 838, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_functorch/aot_autograd.py", line 1201, in forward
    return compiled_fn(full_args)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 315, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
                            ^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/utils.py", line 100, in g
    return f(*args)
           ^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/autograd/function.py", line 575, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 1937, in forward
    fw_outs = call_func_at_runtime_with_args(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
                            ^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 495, in wrapper
    return compiled_fn(runtime_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 689, in inner_fn
    outs = compiled_fn(args)
           ^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/output_code.py", line 460, in __call__
    return self.current_callable(inputs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/_inductor/utils.py", line 2404, in run
    return model(new_inputs)
           ^^^^^^^^^^^^^^^^^
  File "/tmp/torchinductor_root/qo/cqo3uikhoqttxdvnkhrujkln45yocywss2s73k2di42jfnp5a2vc.py", line 4134, in call
    buf379 = empty_strided_cuda((12282, 768), (768, 1), torch.bfloat16)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 22.07 GiB of which 20.44 MiB is free. Process 2708630 has 22.04 GiB memory in use. Of the allocated memory 21.75 GiB is allocated by PyTorch, and 15.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
```
3. ä¸å¯åŠ¨torch_compileã€ä¸å¯åŠ¨grad_checkpointæŠ¥é”™
```
Traceback (most recent call last):
  File "/workspace/model_pretrain.py", line 686, in <module>
    train(args, logger)
  File "/workspace/model_pretrain.py", line 636, in train
    raise e
  File "/workspace/model_pretrain.py", line 597, in train
    train_epoch(
  File "/workspace/model_pretrain.py", line 392, in train_epoch
    outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/model/Model.py", line 223, in forward
    hidden_states = layer(hidden_states, additive_mask)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/model/DecoderLayer.py", line 102, in forward
    attn_out = self.self_attn(self.norm_attn(x), additive_mask)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/model/Attention.py", line 421, in forward
    probs    = self.attn_dropout(probs).to(param_dtype)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/dropout.py", line 70, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/functional.py", line 1425, in dropout
    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 22.07 GiB of which 2.23 GiB is free. Process 3811892 has 19.83 GiB memory in use. Of the allocated memory 19.38 GiB is allocated by PyTorch, and 185.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation. 
```
4. å¯åŠ¨flash_attentionæŠ¥é”™
```
Traceback (most recent call last):
  File "/workspace/model_pretrain.py", line 686, in <module>
    train(args, logger)
  File "/workspace/model_pretrain.py", line 636, in train
    raise e
  File "/workspace/model_pretrain.py", line 597, in train
    train_epoch(
  File "/workspace/model_pretrain.py", line 392, in train_epoch
    outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/model/Model.py", line 223, in forward
    hidden_states = layer(hidden_states, additive_mask)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/model/DecoderLayer.py", line 106, in forward
    ffn_out = self.mlp(self.norm_ffn(x))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/model/MLP.py", line 78, in forward
    x_gate = torch.sigmoid(x_gate)  # [batch_size, seq_len, hidden_dim]
             ^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 22.07 GiB of which 164.44 MiB is free. Process 3879328 has 21.90 GiB memory in use. Of the allocated memory 21.48 GiB is allocated by PyTorch, and 151.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management 
```

</details>

---

<details>
<summary>2025.8.6</summary>

### DONE
1. ä½ç½®ç¼–ç æ›¿æ¢ï¼šDynamic-RoPEæ›¿æ¢XPosEmbedding
2. é‡æ„Attention é‡æ„å¤šå¤´è‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œä¼˜åŒ–å¼ é‡å¹¶è¡Œå’Œä½ç½®ç¼–ç 
- ç§»é™¤KVCacheç›¸å…³ä»£ç ï¼Œç®€åŒ–æ³¨æ„åŠ›æ¨¡å—ç»“æ„
- ä½¿ç”¨ByteDynamicRoPEæ›¿ä»£XPosRotaryEmbeddingå®ç°åŠ¨æ€ä½ç½®ç¼–ç 
- é‡æ„å¼ é‡å¹¶è¡Œé€»è¾‘ï¼Œæ”¹è¿›æƒé‡åˆå§‹åŒ–å’Œæ©ç ç”Ÿæˆ
- ä¼˜åŒ–ä»£ç ç»“æ„ï¼Œå¢å¼ºå¯è¯»æ€§å’Œç»´æŠ¤
3. Model.pyç®€åŒ–æ¨¡å‹ç»“æ„å¹¶ç§»é™¤å†—ä½™ä»£ç 
- ç§»é™¤å¤æ‚çš„åˆå§‹åŒ–é€»è¾‘å’Œè¾…åŠ©æ–¹æ³•
- ç®€åŒ–å‰å‘ä¼ æ’­å’Œç”Ÿæˆé€»è¾‘
- ä¿ç•™æ ¸å¿ƒTransformerç»“æ„
- ä¼˜åŒ–ä»£ç ç»„ç»‡ç»“æ„æé«˜å¯è¯»æ€§
4. DecoderLayerç§»é™¤KVCacheä¾èµ–å¹¶é‡å‘½åmaskå‚æ•°
- åˆ é™¤æœªä½¿ç”¨çš„KVCacheç›¸å…³å¯¼å…¥å’Œå‚æ•°
- å°†additive_maské‡å‘½åä¸ºæ›´æ˜ç¡®çš„padding_mask
- ä¼˜åŒ–å¹¶è¡Œæ®‹å·®å—çš„ä»£ç æ ¼å¼
- æ›´æ–°æµ‹è¯•è¾“å‡ºæ ¼å¼ä»¥æ˜¾ç¤ºè¾“å…¥è¾“å‡ºå½¢çŠ¶
5. æ”¹è¿› ByteMLP æ¨¡å—çš„ä»£ç ç»“æ„å’Œæ–‡æ¡£
- é‡æ„ ByteMLP æ¨¡å—çš„ä»£ç ç»“æ„ï¼Œä½¿å…¶æ›´æ¸…æ™°æ˜“è¯»
- é‡æ–°ç»„ç»‡ç±»æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œæ˜ç¡®æ¨¡å—åŠŸèƒ½å’Œå‚æ•°è¯´æ˜
- ä¼˜åŒ–å‰å‘ä¼ æ’­è¿‡ç¨‹çš„æ³¨é‡Šï¼Œåˆ†æ­¥éª¤è§£é‡Šé—¨æ§æœºåˆ¶
- ç»Ÿä¸€ä»£ç æ ¼å¼å’Œå‘½åè§„èŒƒ
- æ›´æ–°æµ‹è¯•ä»£ç çš„æ³¨é‡Šè¯´æ˜
6. MLPå±‚è°ƒæ•´Dropoutå’Œæ®‹å·®è¿æ¥çš„é¡ºåºä»¥æå‡æ¨¡å‹ç¨³å®šæ€§
ä¿®æ”¹äº†ByteMLPæ¨¡å—ä¸­Dropoutå’Œæ®‹å·®è¿æ¥çš„æ‰§è¡Œé¡ºåºï¼Œå…ˆåº”ç”¨Dropoutå†è¿›è¡Œæ®‹å·®è¿æ¥ã€‚è¿™ç§è°ƒæ•´å¯ä»¥é˜²æ­¢æ®‹å·®è¿æ¥åçš„æ•°å€¼èŒƒå›´è¿‡å¤§ï¼Œæœ‰åŠ©äºæå‡æ¨¡å‹è®­ç»ƒçš„ç¨³å®šæ€§ã€‚

### TODO
1. é‡æ–°æ„å»ºtokenizerçš„è®­ç»ƒ
2. ä¸»æ¨¡å‹åº”ç”¨XPosRotoryEmbeddingä½ç½®ç¼–ç 
3. å®Œå–„æ¨¡å‹é¡¶å±‚åŸºç¡€è®¾è®¡forward()ã€generate()

</details>

---

<details>
<summary>2025.8.7</summary>

### DONE
1. é‡æ„tokenizerè®­ç»ƒè„šæœ¬
- å¯¹è¯æ¨¡å‹é…ç½®
- ç‰¹æ®Štokensé…ç½®
- è§’è‰²æ ‡è®°é…ç½®
- BPEç®—æ³•è®­ç»ƒ+bytelevelå›é€€
2. å®Œå–„æ¨¡å‹é¡¶å±‚è®¾è®¡forwardå‡½æ•°å’Œgenerateå‡½æ•°ï¼Œå¹¶é…ç½®äº†è‡ªå›å½’å‡½æ•°çš„è¾…åŠ©å‡½æ•°
- forwardå‘å‰ä¼ æ’­å‡½æ•°ï¼Œå°†æ¨¡å‹ç»„ä»¶è¿›è¡Œç»„è£…
- generateè‡ªå›å½’ç”Ÿæˆå‡½æ•°
- sample_next_tokené‡‡æ ·å‡½æ•°ï¼Œtop-ké‡‡æ ·ï¼Œç”Ÿæˆæ—¶å¢åŠ top-pã€temperatureå‚æ•°ï¼Œå…è®¸åœ¨ç”Ÿæˆæ—¶è¿›è¡Œtop-kã€top-pé‡‡æ ·æ“ä½œï¼Œé¿å…ç”Ÿæˆé•¿å°¾tokenæˆ–ä½æ¦‚ç‡çš„token
- repetition_penaltyé‡å¤æƒ©ç½šï¼Œåœ¨ç”Ÿæˆæ–‡æœ¬æ—¶ï¼Œæ ¹æ®é‡å¤å‡ºç°çš„tokençš„é¢‘ç‡å¯¹å½“å‰ç”Ÿæˆçš„tokenè¿›è¡Œæƒ©ç½šï¼Œä»è€Œé¿å…ç”Ÿæˆæ–‡æœ¬å‡ºç°ä½è´¨é‡å†…å®¹
3. æ„å»ºæ¨¡å‹é¢„è®­ç»ƒè„šæœ¬
- æ„å»ºäº†æ•´ä½“çš„ä¸»è¦å‡½æ•°
  - set_environment() æ¨¡å‹è®­ç»ƒç¯å¢ƒé…ç½®å‡½æ•°
  - cosine_annealing_lr() å­¦ä¹ ç‡è°ƒåº¦å™¨å‡½æ•°
  - parse_args() è§£æè„šæœ¬å‚æ•°å‡½æ•°
  - init_model() åˆå§‹åŒ–æ¨¡å‹å‡½æ•°
  - eval() æ¨¡å‹è¯„ä¼°å‡½æ•°
  - train_epoch() å•è½®è®­ç»ƒå‡½æ•°
  - train() æ¨¡å‹è®­ç»ƒå‡½æ•°

### TODO
1. tokenizerè§£å†³é—®é¢˜ - åå¤„ç†å™¨æ¨¡æ¿åªå®šä¹‰äº†singleå’Œpairæ ¼å¼ï¼Œç¼ºå°‘å¯¹å¤šè½®å¯¹è¯æˆ–æ›´å¤æ‚åœºæ™¯çš„æ”¯æŒï¼Œè§£ç å™¨å’Œåå¤„ç†å™¨çš„tokenæ›¿æ¢ç¬¦éœ€ä¿æŒåŒæ­¥ã€‚
2. é‡æ„æ¨¡å‹è®­ç»ƒå‚æ•°æ–‡ä»¶
3. å®Œå–„æ¨¡å‹é¢„è®­ç»ƒè„šæœ¬å¹¶è¿›è¡Œæµ‹è¯•

</details>

---

<details>
<summary>2025.8.8</summary>

### DONE
1. ä¼˜åŒ–æ•°æ®é›†åŠ è½½å™¨
- ä¸ºBaseDatasetæ·»åŠ BOS/EOS tokenè‡ªåŠ¨æ³¨å…¥é€»è¾‘
- æ”¹è¿›_pad_and_maskæ–¹æ³•è¿”å›ç±»å‹ä¸ºtorch.Tensor
- åœ¨PretrainDatasetä¸­æ”¯æŒEOS tokenå¹¶ä¼˜åŒ–tokené¢„ç•™é€»è¾‘
- æ·»åŠ æ•°æ®é›†æµ‹è¯•ç”¨ä¾‹ä¾¿äºéªŒè¯åŠŸèƒ½
2. å®Œå–„æ¨¡å‹é¢„è®­ç»ƒè„šæœ¬ï¼Œä¼˜åŒ–ä»£ç ç»“æ„å’ŒåŠŸèƒ½å®ç°
- é‡æ„å‚æ•°è§£æå‡½æ•°ï¼Œæ”¯æŒYAMLé…ç½®æ–‡ä»¶è¯»å–å’ŒåµŒå¥—å‘½åç©ºé—´è½¬æ¢
- ä¼˜åŒ–ç¯å¢ƒè®¾ç½®å‡½æ•°ï¼Œå¢å¼ºæ—¥å¿—è®°å½•å’Œè®¾å¤‡é€‰æ‹©é€»è¾‘
- é‡å†™å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œæ”¹è¿›ä½™å¼¦é€€ç«ç®—æ³•å®ç°
- å®Œå–„æ¨¡å‹åˆå§‹åŒ–å’Œè¯„ä¼°å‡½æ•°ï¼Œå¢åŠ æ··åˆç²¾åº¦è®­ç»ƒæ”¯æŒ
- é‡æ„è®­ç»ƒå¾ªç¯ï¼Œæ”¯æŒæ¢¯åº¦ç´¯ç§¯å’Œå‘¨æœŸæ€§éªŒè¯

### TODO
1. æ¨¡å‹é¢„è®­ç»ƒè„šæœ¬ä¼˜åŒ–ä¸å®Œå–„
- ä¼˜åŒ–æ¨¡å‹é¢„è®­ç»ƒè„šæœ¬train_epochä¸­çš„æŸå¤±å‡½æ•°ä¸padding_maskè®¾ç½®ä¸è®¡ç®—
- å®Œå–„æ¨¡å‹é¢„è®­ç»ƒè„šæœ¬train()æ¨¡å‹é¢„è®­ç»ƒä¸»ä½“å‡½æ•°
2. æ£€æŸ¥æ•°æ®é›†åŠ è½½å™¨ä¸­attention_maskè®¾è®¡ä¸æ¨¡å‹ä¸»ä½“ä¸­çš„padding_maskéœ€æ±‚æ˜¯å¦ä¸€è‡´ï¼Œå¦‚æœä¸ä¸€è‡´è¿›è¡Œç›¸å¯¹åº”çš„ä¿®å¤
3. é‡æ„é…ç½®æ–‡ä»¶

</details>

---

<details>
<summary>2025.8.9</summary>

### DONE
1. PretrainDatasetã€SFTDatasset æ•°æ®é›†åŠ è½½å™¨ä¿®å¤
é‡æ„æ•°æ®é›†å¤„ç†é€»è¾‘å¹¶ä¼˜åŒ–æ©ç ç”Ÿæˆ
- ä¿®å¤input_idsã€labelsã€attention_maskã€loss_maskç”Ÿæˆé€»è¾‘
  - è¾“å…¥åºåˆ—ï¼š[BOS, T1, T2, T3, T4, T5, T6, T7, EOS]
  - æ ·æœ¬æ‹†åˆ†ï¼š
    - Xï¼š[BOS, T1, T2, T3, T4, T5, T6, T7] â†’ æ¨¡å‹è¾“å…¥ä¸Šä¸‹æ–‡
    - Yï¼š[T1, T2, T3, T4, T5, T6, T7, EOS] â†’ æ¨¡å‹é¢„æµ‹ç›®æ ‡
  - æŸå¤±æ©ç ï¼š
    - æœ‰æ•ˆä½ç½®ï¼š[0, 1, 1, 1, 1, 1, 1, 1, 1] â†’ ä»…å¯¹T1-EOSè®¡ç®—æŸå¤±
- å°†ç‰¹æ®Šæ ‡è®°ä»ç¡¬ç¼–ç æ”¹ä¸ºé€šè¿‡æ„é€ å‡½æ•°ä¼ å…¥ï¼Œæé«˜çµæ´»æ€§
- é‡å‘½å `generate_loss_mask` ä¸º `_generate_loss_mask` è¡¨ç¤ºå†…éƒ¨æ–¹æ³•
- ä¼˜åŒ–æ©ç ç”Ÿæˆé€»è¾‘ï¼Œä½¿ç”¨åˆ‡ç‰‡æ“ä½œæ›¿ä»£å¾ªç¯
- æ·»åŠ  attention_mask åˆ°è¿”å›å­—å…¸å¹¶ç»Ÿä¸€ä½¿ç”¨ bool ç±»å‹
- åœ¨ labels ä¸­é loss_mask ä½ç½®è®¾ç½®ä¸º -100 é¿å…è®¡ç®—æŸå¤±
- æ”¹è¿›ä»£ç æ ¼å¼å’Œæ³¨é‡Šæ¸…æ™°åº¦
2. MultiHeadSelfAttention ä¸»è¦ä¿®å¤å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸­attention_maskçš„è°ƒæ•´ä»¥åŠattention_maskä¸causal_maskèåˆçš„é€»è¾‘
- ä¼˜åŒ–æ³¨æ„åŠ›æ©ç ç”Ÿæˆé€»è¾‘å¹¶é‡å‘½åå‚æ•°
- é‡æ„æ³¨æ„åŠ›æ©ç ç”Ÿæˆé€»è¾‘ï¼Œä½¿ç”¨æ›´æ¸…æ™°çš„å˜é‡å‘½åå’Œæ¡ä»¶åˆ¤æ–­ã€‚
- å°†padding_maskå‚æ•°é‡å‘½åä¸ºattention_maskä»¥æ›´å‡†ç¡®åæ˜ å…¶ç”¨é€”ï¼Œå¹¶æ”¹è¿›æ©ç åˆå¹¶é€»è¾‘ã€‚
- å°†æœ€å°æ©ç å€¼ä»torch.finfo(dtype).minæ”¹ä¸ºå›ºå®šå€¼-1e9ä»¥æé«˜ç¨³å®šæ€§ã€‚
3. DecoderLayerå±‚ è°ƒæ•´ä¿®å¤ï¼Œé‡å‘½åpadding_maskä¸ºattention_maskå¹¶ä¼˜åŒ–å¹¶è¡Œæ®‹å·®è·¯å¾„
- å°†padding_maskå‚æ•°é‡å‘½åä¸ºæ›´é€šç”¨çš„attention_maskä»¥æå‡ä»£ç å¯è¯»æ€§
- åœ¨å¹¶è¡Œæ®‹å·®è·¯å¾„ä¸­ä¸ºFFNæ·»åŠ ç‹¬ç«‹çš„å½’ä¸€åŒ–å±‚ï¼Œä¸é¡ºåºæ®‹å·®è·¯å¾„ä¿æŒä¸€è‡´
4. Modelæ¨¡å‹ä¸»ä½“ è°ƒæ•´ä¿®å¤ï¼Œå°†padding_maské‡å‘½åä¸ºattention_maskå¹¶ç®€åŒ–æŸå¤±è®¡ç®—
- å°†å‚æ•°åä»padding_maskæ”¹ä¸ºæ›´é€šç”¨çš„attention_maskä»¥ä¿æŒä¸€è‡´æ€§
- ç§»é™¤ä¸å¿…è¦çš„æ ‡ç­¾ç§»ä½æ“ä½œï¼Œç›´æ¥ä½¿ç”¨åŸå§‹logitså’Œlabelsè®¡ç®—æŸå¤±
5. model/config.py ç§»é™¤æœªä½¿ç”¨çš„tie_word_embeddingså‚æ•°,æ¸…ç†æ¨¡å‹é…ç½®ä¸­æœªä½¿ç”¨çš„ç»‘å®šè¯åµŒå…¥å‚æ•°ï¼Œç®€åŒ–é…ç½®é€»è¾‘
6. configs/pretrain_config.yaml é‡æ„é¢„è®­ç»ƒé…ç½®æ–‡ä»¶ç»“æ„å¹¶æ›´æ–°å‚æ•°
- é‡æ–°ç»„ç»‡é…ç½®æ–‡ä»¶ç»“æ„ï¼Œå°†ç›¸å…³é…ç½®åˆ†ç»„æ›´æ¸…æ™°
- æ›´æ–°æ¨¡å‹å‚æ•°å’Œè®­ç»ƒé…ç½®ä»¥åŒ¹é…æœ€æ–°éœ€æ±‚
- ä¼˜åŒ–è®­ç»ƒé…ç½®å‚æ•°å’Œæ—¥å¿—è®¾ç½®
- æ·»åŠ ç”Ÿæˆé…ç½®ç”¨äºæ¨ç†åœºæ™¯
- ç§»é™¤å†—ä½™é…ç½®é¡¹ï¼Œç®€åŒ–æ–‡ä»¶å†…å®¹
- è°ƒæ•´å‚æ•°å‘½åä»¥ä¿æŒä¸€è‡´æ€§
7. é‡æ„æ—¥å¿—æ¨¡å—ï¼Œä½¿ç”¨TimedRotatingFileHandlerå¹¶æ”¹è¿›å½©è‰²è¾“å‡º
- ç§»é™¤colorlogä¾èµ–ï¼Œæ”¹ç”¨coloramaå®ç°å½©è‰²æ—¥å¿—
- å°†RotatingFileHandleræ›¿æ¢ä¸ºTimedRotatingFileHandlerä»¥æ”¯æŒæŒ‰æ—¶é—´è½®è½¬æ—¥å¿—
- æ–°å¢æ—¥å¿—çº§åˆ«å­—ç¬¦ä¸²è½¬æ¢åŠŸèƒ½
- ç®€åŒ–æ—¥å¿—é…ç½®æ¥å£ï¼Œåˆå¹¶build_loggerå’Œget_loggeråŠŸèƒ½
- æ”¹è¿›å¼‚å¸¸å¤„ç†é€»è¾‘ï¼Œç§»é™¤å…¨å±€å¼‚å¸¸å¤„ç†å™¨
8. é‡æ„æ£€æŸ¥ç‚¹ç®¡ç†å™¨ä»¥æ”¯æŒåŸå­ä¿å­˜å’Œåˆ†å¸ƒå¼è®­ç»ƒ
- ä½¿ç”¨ Path æ›¿ä»£å­—ç¬¦ä¸²è·¯å¾„å¤„ç†
- å®ç°åŸå­åŒ–ä¿å­˜æœºåˆ¶é˜²æ­¢æŸå
- æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒçš„ä¸»è¿›ç¨‹åˆ¤æ–­
- æ”¹è¿›æœ€ä½³æ¨¡å‹è·Ÿè¸ªå’Œæ—§æ£€æŸ¥ç‚¹æ¸…ç†
- æ·»åŠ ä¿¡å·å¤„ç†ç”¨äºç´§æ€¥ä¿å­˜
- å¢åŠ ç±»å‹æ³¨è§£å’Œæ–‡æ¡£å­—ç¬¦ä¸²
9. model_pretrain.py å®Œå–„è®­ç»ƒè„šæœ¬ï¼Œå¢å¼ºæ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°åŠŸèƒ½
- æ„å»ºæ•´ä½“çš„æ¨¡å‹è®­ç»ƒtrain()å‡½æ•°
- æ·»åŠ NLTKè¯„ä¼°æŒ‡æ ‡(BLEU/ROUGE/METEOR)æ”¯æŒ
- é‡æ„æ—¥å¿—ç³»ç»Ÿä½¿ç”¨setup_loggerç»Ÿä¸€ç®¡ç†
- æ”¹è¿›å­¦ä¹ ç‡è°ƒåº¦å™¨æ”¯æŒåŠ¨æ€æœ€å°å­¦ä¹ ç‡è®¡ç®—
- ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹å¢åŠ æ¢¯åº¦ç´¯ç§¯æ®‹ä½™å¤„ç†
- å®Œå–„è¯„ä¼°å‡½æ•°å¢åŠ æ–‡æœ¬ç”Ÿæˆè´¨é‡è¯„ä¼°
- æ·»åŠ SwanLabå®éªŒè·Ÿè¸ªé›†æˆ

### TODO
1. æ›´æ–°æ¨¡å‹æ¯ä¸ªå•å…ƒçš„æµ‹è¯•è„šæœ¬ï¼Œå¯¹æ¯ä¸ªç»„ä»¶è¿›è¡Œè¯¦ç»†æµ‹è¯•ï¼Œå¹¶ä¿®å¤å¯¹åº”bug
2. æ›´æ–°æ¨¡å‹é¢„è®­ç»ƒç›¸å…³çš„ç»„ä»¶æµ‹è¯•è„šæœ¬ï¼Œå¹¶ä¿®å¤å¯¹åº”bug
3. æµ‹è¯•æ¨¡å‹é¢„è®­ç»ƒè„šæœ¬ï¼Œè°ƒè¯•ç›¸å…³bug
4. æ›´æ–°ä»£ç æ–‡æ¡£ï¼Œæå‡ä»£ç å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§

</details>

---

<details>
<summary>2025.8.10</summary>

### DONE
1. å®Œå–„ä¾èµ–åŒ…ç›¸å…³é…ç½®
- æ·»åŠ NLPç›¸å…³ä¾èµ–åŒ…,æ·»åŠ sentencepieceã€nltkã€rouge-scoreç­‰NLPè¯„ä¼°
- æ·»åŠ tokenizerè®­ç»ƒæ‰€éœ€çš„ä¾èµ–é¡¹,æ·»åŠ tokenizersã€datasets
2. MultiHeadSelfAttentionä¿®å¤å¤šå¤´æ³¨æ„åŠ›è®¡ç®—ä¸­çš„æ•°æ®ç±»å‹ä¸ä¸€è‡´é—®é¢˜
- å°†æ³¨æ„åŠ›æƒé‡è½¬æ¢ä¸ºä¸å€¼å¼ é‡ç›¸åŒçš„æ•°æ®ç±»å‹ï¼Œé¿å…è®¡ç®—æ—¶å‡ºç°ç±»å‹ä¸åŒ¹é…é”™è¯¯
3. model/__init__ æ¨¡å‹å¯¼å‡ºæ–‡ä»¶,ç»Ÿä¸€æ¨¡å—å‘½åè§„èŒƒå¹¶æ·»åŠ ByteEmbeddingå¯¼å‡º
- å°†ä¸»è¦ç±»å’Œæ¨¡å—é‡å‘½åä»¥ç»Ÿä¸€ä½¿ç”¨"Byte"å‰ç¼€ï¼Œæé«˜ä»£ç ä¸€è‡´æ€§
- æ·»åŠ ByteEmbeddingåˆ°å¯¼å‡ºåˆ—è¡¨ä»¥æ”¯æŒæ–°çš„åµŒå…¥å±‚åŠŸèƒ½
4. æ›´æ–°å¹¶æµ‹è¯•æ¯ä¸ªå•å…ƒæ¨¡å—
- æ›´æ–°Attentionå¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶æµ‹è¯•æ¨¡å—
  - æ·»åŠ æµ‹è¯•è¾…åŠ©å‡½æ•°å’Œ fixture ä»¥æ”¯æŒå¤šç§æ•°æ®ç±»å‹æµ‹è¯•
  - å¢åŠ å¯¹é‡å¤KVã€å› æœæ©ç ã€çª—å£æ³¨æ„åŠ›ç­‰è¾…åŠ©æ–¹æ³•çš„æµ‹è¯•
  - æ·»åŠ å‰å‘ä¼ æ’­çš„å½¢çŠ¶å’Œç¨³å®šæ€§æµ‹è¯•
  - ç§»é™¤è¿‡æ—¶çš„ KVCache ç›¸å…³æµ‹è¯•
- é‡æ„BaseDatasetsã€PretrainDatasetsã€SFTDatasetsæ•°æ®é›†åŠ è½½å™¨æµ‹è¯•æ¨¡å—ï¼Œå¹¶å¢åŠ æ›´å¤šæµ‹è¯•ç”¨ä¾‹
  - é‡æ„æµ‹è¯•æ–‡ä»¶ç»“æ„ï¼Œå¢åŠ å¯¹BaseDatasetã€PretrainDatasetå’ŒSFTDatasetçš„æµ‹è¯•è¦†ç›–
  - æ·»åŠ å¯¹CSVæ ¼å¼æ•°æ®çš„æ”¯æŒæµ‹è¯•
  - å®Œå–„tokenizerå¤„ç†é€»è¾‘çš„æµ‹è¯•
  - å¢åŠ å¯¹æ¨¡æ¿æ ¼å¼åŒ–å’Œç¼ºå¤±å­—æ®µçš„æµ‹è¯•
- æ›´æ–°ByteMLPæµ‹è¯•
  - æ›´æ–°æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹ä»¥ä½¿ç”¨æ–°çš„ByteMLPç±»ï¼ŒéªŒè¯é—¨æ§æœºåˆ¶å’Œå½’ä¸€åŒ–å±‚çš„æ­£ç¡®æ€§ã€‚
  - ç§»é™¤å¯¹æ—§MLPç±»çš„å¼•ç”¨ï¼Œå¹¶æ·»åŠ å¯¹æ–°åŠŸèƒ½çš„æµ‹è¯•è¦†ç›–ã€‚
- é‡æ„Position_Embeddingæµ‹è¯•æ–‡ä»¶å¹¶æ·»åŠ æ–°æµ‹è¯•ç”¨ä¾‹
  - å°†æµ‹è¯•ç±»ä»XPosRotaryEmbeddingæ”¹ä¸ºByteDynamicRoPE
  - æ–°å¢æµ‹è¯•ç”¨ä¾‹éªŒè¯åˆå§‹åŒ–ã€åŸºç¡€é¢‘ç‡è®¡ç®—ã€NTKç¼©æ”¾å› å­è¡Œä¸ºç­‰
  - æ·»åŠ æ—‹è½¬å½¢çŠ¶å’Œæ•°å€¼æ­£ç¡®æ€§æµ‹è¯•
  - åŒ…å«ç¼“å­˜é‡å»ºå’ŒèŒƒæ•°ä¿æŒçš„éªŒè¯
- æ›´æ–°å±‚å½’ä¸€åŒ–æµ‹è¯•ç”¨ä¾‹ä»¥ä½¿ç”¨ByteRMSNormæ›¿ä»£RMSNorm
5. ä¿®å¤å¤šå¤´æ³¨æ„åŠ›è®¡ç®—ä¸­çš„æ•°æ®ç±»å‹ä¸ä¸€è‡´é—®é¢˜
- å°†æ³¨æ„åŠ›æƒé‡è½¬æ¢ä¸ºä¸å€¼å¼ é‡ç›¸åŒçš„æ•°æ®ç±»å‹ï¼Œé¿å…è®¡ç®—é”™è¯¯
6. ä¿®å¤SFTæ•°æ®é›†åŠ è½½å™¨
- ä¼˜åŒ–ç‰¹æ®Šæ ‡è®°å¤„ç†å¹¶æ”¹è¿›æ©ç è®¡ç®—é€»è¾‘
- å°† start_tokens å’Œ end_tokens å¤„ç†é€»è¾‘ç»Ÿä¸€ä¸ºæ”¯æŒå­—ç¬¦ä¸²æˆ–IDåˆ—è¡¨
- æ”¹è¿›æ©ç è®¡ç®—æ–¹å¼ï¼Œä½¿ç”¨å¼ é‡æ“ä½œæ›¿ä»£åˆ—è¡¨æ“ä½œæé«˜æ•ˆç‡
- ä¿®å¤æ ‡ç­¾å¤„ç†ä¸­çš„ç±»å‹ä¸ä¸€è‡´é—®é¢˜
- æ›´æ–°æµ‹è¯•ç”¨ä¾‹ä»¥éªŒè¯ä¿®æ”¹åçš„åŠŸèƒ½
7. é‡æ„Byte-Transformeræ¨¡å‹é¢„è®­ç»ƒé…ç½®æ–‡ä»¶
- æ·»åŠ ç»Ÿä¸€çš„é¢„è®­ç»ƒ/ç»§ç»­è®­ç»ƒé…ç½®æ–‡ä»¶ï¼ŒåŒ…å«å®éªŒã€æ•°æ®ã€æ¨¡å‹æ¶æ„ã€è®­ç»ƒã€ç”Ÿæˆå’Œæ—¥å¿—ç­‰æ¨¡å—çš„é…ç½®å‚æ•°
- è®©é…ç½®æ–‡ä»¶ç»“æ„æ›´æ¸…æ™°ï¼Œæ›´å…·æœ‰å¯è¯»æ€§ã€å¯ç»´æŠ¤æ€§

### TODO
1. ä¼˜åŒ–tokenizerè®­ç»ƒ
- æ”¯æŒä¸­æ–‡ç¼–ç 
- æ›´æ–°å¯¹è¯æ¨¡æ¿
- è§£å†³token_endå’Œpadä½¿ç”¨åŒæ ·çš„æ ‡è®°é”™è¯¯é—®é¢˜
- æå‡è®­ç»ƒé€Ÿåº¦
- å°è¯•è¿›è¡Œtokenizerè¿›è¡Œè®­ç»ƒ
2. æµ‹è¯•å¹¶ä¿®å¤æ¨¡å‹é¢„è®­ç»ƒè„šæœ¬ï¼Œç»™å‡ºæœ€ç»ˆçš„æ¨¡å‹é¢„è®­ç»ƒè„šæœ¬
- æ”¯æŒä½¿ç”¨å‘½ä»¤è¡Œ + configs/model_pretrain.yaml å¯¹è®­ç»ƒå‚æ•°è¿›è¡Œé…ç½®ï¼Œå¹¶ç›´æ¥è¿›è¡Œæ¨¡å‹è®­ç»ƒ

</details>

---

<details>
<summary>2025.8.11</summary>

### DONE
1. åœ¨.gitignoreä¸­æ·»åŠ sources/ç›®å½•
2. configs/model_pretrain.yaml ä¿®æ­£é…ç½®æ–‡ä»¶ä¸­å‚æ•°é”™è¯¯å¹¶æ›´æ–°æ•°æ®è·¯å¾„
- ä¿®å¤use_swanlabæ‹¼å†™é”™è¯¯
- æ›´æ–°è®­ç»ƒå’ŒéªŒè¯æ•°æ®è·¯å¾„
- ç§»é™¤tie_word_embeddingså‚æ•°å¹¶æ·»åŠ deviceé…ç½®
3. ByteEmbedding ä¼˜åŒ–åµŒå…¥å±‚å‚æ•°å‘½åå¹¶æ·»åŠ æµ‹è¯•ç”¨ä¾‹
é‡æ„åµŒå…¥å±‚å‚æ•°å‘½åä»¥æé«˜å¯è¯»æ€§ï¼Œå¹¶æ·»åŠ æµ‹è¯•ç”¨ä¾‹éªŒè¯åŠŸèƒ½æ­£ç¡®æ€§
4. model_pretrain.py é‡æ„é…ç½®è§£æå’Œè®¾å¤‡å¤„ç†é€»è¾‘
- å°†åµŒå¥—é…ç½®å±•å¹³ä¸ºä¸€çº§ç»“æ„ï¼Œç®€åŒ–å‚æ•°è®¿é—®
- æ–°å¢è®¾å¤‡è§£æå‡½æ•°ï¼Œæ”¯æŒå¤šGPUé…ç½®
- ä¼˜åŒ–SwanLabåˆå§‹åŒ–é€»è¾‘ï¼Œå¢åŠ é…ç½®æ£€æŸ¥
- ç»Ÿä¸€è®­ç»ƒå‚æ•°è®¿é—®æ–¹å¼ï¼Œç§»é™¤åµŒå¥—ç»“æ„
- æ·»åŠ å‘½ä»¤è¡Œå‚æ•°æ”¯æŒï¼Œæå‡è„šæœ¬å¯ç”¨æ€§

### TODO
1. æ¨¡å‹é¢„è®­ç»ƒè„šæœ¬ä¸­ä¿®å¤å‚æ•°è¯»å–ç›¸å…³çš„BUG
2. æµ‹è¯•æ¨¡å‹é¢„è®­ç»ƒè„šæœ¬ï¼Œä¿®å¤å®Œå–„ç›¸å…³åŠŸèƒ½ã€‚

### DEBUG
1. è§£å†³å¯åŠ¨æ¨¡å‹é¢„è®­ç»ƒè„šæœ¬æ—¶æŠ¥é”™ï¼š
```
Traceback (most recent call last):
  File "d:\Objects\StellarByte\model_pretrain.py", line 845, in <module>        
    train(args.config)
  File "d:\Objects\StellarByte\model_pretrain.py", line 700, in train
    model, tokenizer = init_model(config, device)
  File "d:\Objects\StellarByte\model_pretrain.py", line 269, in init_model      
    model = ByteModel(model_config)
  File "d:\Objects\StellarByte\model\Model.py", line 34, in __init__
    self.token_embedding = ByteEmbedding(args)
  File "d:\Objects\StellarByte\model\EmbeddingLayer.py", line 43, in __init__   
    self.embed_tokens  = nn.Embedding(
  File "D:\Develop_Tools\Anconda3\envs\LLM\lib\site-packages\torch\nn\modules\sparse.py", line 167, in __init__
    torch.empty((num_embeddings, embedding_dim), **factory_kwargs),
TypeError: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:
 * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, *, torch.memory_format memory_format = None, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
```
ByteEMbedding ä¸­æç¤ºä¿¡æ¯ï¼š
```
vocab_size: namespace(use_swanlab='trua', project_name='ByteLM-Pretrain', run_name='baseline-158M', mode='cloud', api_key='', tokenizer_path='./tokenizer', train_data='./data/test/test_train.jsonl', eval_data='./data/test_eval.jsonl', vocab_size=32768, model_dim=768, num_layers=12, max_seq_len=2048, layer_norm_eps='1e-5', initializer_range=0.02, layerscale_init='1e-5', parallel_residual=True, num_heads=16, num_kv_heads=8, use_flash_attention=False, attention_window_size=0, attention_dropout_prob=0.1, base_theta=10000.0, ntk_alpha=1.0, use_cache=True, key_cache_dtype='float16', value_cache_dtype='float16', hidden_dim=3072, dim_multiplier=4, hidden_dropout_prob=0.1, residual_dropout_prob=0.1, drop_path_prob=0.0, tensor_parallel_size=1, train_epochs=10, batch_size=32, learning_rate='3e-4', min_lr_ratio=0.1, weight_decay=0.1, beta1=0.9, beta2=0.98, warmup_ratio=0.02, plateau_ratio=0.01, gradient_accumulation_steps=4, max_grad_norm=1.0, num_workers=8, use_cuda=True, device='cpu', mixed_precision=True, output_dir='./checkpoints', save_epochs=1, save_interval=1000, log_interval=50, eval_steps=500, eval_batch_size=16, temperature=1.0, top_k=50, top_p=0.9, repetition_penalty=1.2, repetition_context=512, logger_name='StellarByte', log_dir='logs', log_file='StellarByte_pretrain.log', log_level='DEBUG', console_level='INFO', file_level='DEBUG', use_color=True, rotation='midnight', backup_count=7, is_rank_0=True) (<class 'types.SimpleNamespace'>)
model_dim: 768 (<class 'int'>)
tp_size: 1 (<class 'int'>)
embed_dim_per_partition: 768 (<class 'int'>)
```

</details>

---

<details>
<summary>20025.8.12</summary>

### MileStone
**å®ç°åŸºç¡€çš„Byte-Transformeræ¨¡å‹å¹¶æˆåŠŸéªŒè¯äº†å•å¡è®­ç»ƒ**

### DONE
1. model_pretrain.py ä¼˜åŒ–é…ç½®å¤„ç†å’Œæ•°æ®é›†åˆå§‹åŒ–,ä¿®å¤è®­ç»ƒæŸå¤±è®¡ç®—å’Œnltkèµ„æºä¸‹è½½é—®é¢˜,æ·»åŠ æ£€æŸ¥ç‚¹ç®¡ç†åŠŸèƒ½ä»¥æ”¯æŒæ¨¡å‹æ¢å¤å’Œæœ€ä½³æ¨¡å‹ä¿å­˜
- æ·»åŠ ç¯å¢ƒå˜é‡æ£€æŸ¥é¿å…NLTKèµ„æºé‡å¤ä¸‹è½½
- æ”¹è¿›é…ç½®å‚æ•°è½¬æ¢é€»è¾‘ï¼Œæ”¯æŒè‡ªåŠ¨ç±»å‹æ¨æ–­
- é‡æ„æ¨¡å‹é…ç½®åˆå§‹åŒ–ï¼Œæ˜¾å¼æå–æ‰€éœ€å‚æ•°ï¼Œè§£å†³å¯åŠ¨æ¨¡å‹é¢„è®­ç»ƒè„šæœ¬æ—¶æŠ¥é”™
- ç®€åŒ–æ•°æ®é›†åˆå§‹åŒ–å‚æ•°ï¼Œç»Ÿä¸€ä½¿ç”¨data_path
- ä¿®å¤è®­ç»ƒè¿‡ç¨‹ä¸­æŸå¤±è®¡ç®—ä¸å‡†ç¡®çš„é—®é¢˜ï¼Œè°ƒæ•´æ¢¯åº¦ç´¯ç§¯é€»è¾‘ä»¥æ­£ç¡®ç»Ÿè®¡tokençº§æŸå¤±
- æ·»åŠ nltk punktåˆ†è¯å™¨èµ„æºä¸‹è½½ï¼Œæ”¹è¿›åˆ†è¯æ–¹å¼ä»ç©ºæ ¼åˆ‡åˆ†åˆ°nltkåˆ†è¯
- ä¿®å¤meteor_scoreè®¡ç®—æ—¶å‚æ•°ä¼ é€’é”™è¯¯çš„é—®é¢˜
- å¼•å…¥CheckpointManagerç±»å®ç°æ¨¡å‹æ£€æŸ¥ç‚¹ç®¡ç†
- æ”¯æŒè®­ç»ƒä¸­æ–­æ¢å¤å’Œæœ€ä½³æ¨¡å‹è‡ªåŠ¨ä¿å­˜
- æ·»åŠ å¤šè¿›ç¨‹å®‰å…¨æ£€æŸ¥å’Œä¿¡å·å¤„ç†
- æ”¹è¿›è®­ç»ƒæ—¥å¿—è®°å½•å’Œè¯„ä¼°æŒ‡æ ‡è·Ÿè¸ª
- ä¿®æ”¹loggeråç§°ä»¥æé«˜å¯è¯†åˆ«æ€§
- å°†SimpleNamespaceé…ç½®è½¬æ¢ä¸ºå­—å…¸ä»¥ä¾¿SwanLabæ­£ç¡®è®°å½•é…ç½®å‚æ•°
2. configs/model_pretrain.yaml ä¿®æ­£è®­ç»ƒå’ŒéªŒè¯æ•°æ®è·¯å¾„é…ç½®é”™è¯¯
- å°†è®­ç»ƒæ•°æ®å’ŒéªŒè¯æ•°æ®çš„è·¯å¾„ä»"./data"æ›´æ­£ä¸º"./datasets"ï¼Œä»¥åŒ¹é…å®é™…é¡¹ç›®ç›®å½•ç»“æ„
- å®Œå–„å®éªŒè®¾ç½®éƒ¨åˆ†çš„å‚æ•°é…ç½®
- æ·»åŠ å®éªŒéƒ¨åˆ†ä½¿ç”¨è¯´æ˜æ³¨é‡Š
- å°†æ£€æŸ¥ç‚¹ç›¸å…³é…ç½®ä» training éƒ¨åˆ†æå–åˆ°ç‹¬ç«‹çš„ checkpoints éƒ¨åˆ†ï¼Œå¹¶å¢åŠ æ›´å¤šæ§åˆ¶é€‰é¡¹å¦‚æœ€å¤§ä¿å­˜æ•°é‡ã€ç›‘æ§æŒ‡æ ‡ç­‰ã€‚åŒæ—¶è°ƒæ•´äº†æ—¥å¿—ä¿å­˜çš„å±‚çº§ç»“æ„ä»¥æé«˜é…ç½®æ–‡ä»¶çš„å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚
3. Model.py ç»Ÿä¸€ä½¿ç”¨num_layersä»£æ›¿n_layerså‚æ•°å
- å°†æ¨¡å‹åˆå§‹åŒ–ä¸­çš„å‚æ•°åä»n_layersç»Ÿä¸€æ”¹ä¸ºnum_layersä»¥ä¿æŒå‘½åä¸€è‡´æ€§ï¼Œå¹¶æ›´æ–°ç›¸å…³åˆå§‹åŒ–é€»è¾‘
4. model/utils/DropPath.py å¢å¼ºDropPathæ¨¡å—åŠŸèƒ½å¹¶æ·»åŠ è¡°å‡è®¡åˆ’
- æ·»åŠ çº¿æ€§/ä½™å¼¦è¡°å‡è®¡åˆ’æ”¯æŒï¼Œå®ç°DDPåŒæ­¥æ©ç åŠŸèƒ½
- æ”¯æŒè‡ªåŠ¨æ··åˆç²¾åº¦å’Œä»»æ„è¾“å…¥ç»´åº¦
- æ·»åŠ è¯¦ç»†æ–‡æ¡£è¯´æ˜å’Œæµ‹è¯•ç”¨ä¾‹
5. model/utils/KVCache.py é‡æ„å·¥ä¸šçº§KVç¼“å­˜ç³»ç»Ÿç”¨äºTransformeræ¨¡å‹ï¼Œæ”¯æŒé«˜æ•ˆé”®å€¼ç¼“å­˜ç®¡ç†ï¼ŒåŒ…æ‹¬ï¼š
- é¢„åˆ†é…å›ºå®šå½¢çŠ¶ç¼“å†²åŒº
- æ”¯æŒæ‰¹é‡è¿½åŠ å’Œå—å†™å…¥æ“ä½œ
- æä¾›æŸæœç´¢é‡æ’åºå’Œå‰ªæåŠŸèƒ½
- å®ç°çŠ¶æ€ä¿å­˜/åŠ è½½å’Œåˆ†å¸ƒå¼åˆ†ç‰‡
- æ”¯æŒè®¾å¤‡ç®¡ç†å’Œå†…å­˜ä¼˜åŒ–
6. æµ‹è¯•cpuè®­ç»ƒã€å•å¡è®­ç»ƒæˆåŠŸ

### TODO
1. æµ‹è¯•å¤šå¡è®­ç»ƒ
2. ä¸ºæ¨¡å‹æ·»åŠ KVCacheç¼“å­˜æ”¯æŒï¼Œæ„å»ºè„šæœ¬å¹¶è¿›è¡Œæµ‹è¯•ä¿®å¤å¯¹åº”BUG
3. æ„å»ºæ£€æŸ¥ç‚¹ç®¡ç†ç±»ï¼Œç»Ÿä¸€ç®¡ç†å’ŒåŠ è½½å¤šä¸ªå®éªŒçš„æ£€æŸ¥ç‚¹ï¼Œæ„å»ºå®éªŒè„šæœ¬è¿›è¡Œæµ‹è¯•å¹¶ä¿®å¤å¯¹åº”bug
4. ä¼˜åŒ–æ•°æ®é›†åŠ è½½å™¨ï¼Œä¸è¦ä¸€æ¬¡æ€§å…¨éƒ¨åŠ è½½ï¼Œåˆ†æ‰¹æ¬¡åŠ è½½ï¼Œå‡å°‘å†…å­˜å ç”¨
5. ä¼˜åŒ–æ¨¡å‹é¢„è®­ç»ƒï¼Œæ·»åŠ æ—©åœæœºåˆ¶ï¼ŒèŠ‚çœè®­ç»ƒæ—¶é—´ã€‚

</details>

---

<details>
<summary>2025.8.13 - 2028.8.14</summary>

### MileStone
**å®ç°å¸¦KVCache çš„Byte-Transformeræ¨¡å‹ã€‚**

### DONE
1. utils/checkpoint.py æ·»åŠ checkpointsåŠŸèƒ½ç±»ï¼Œæä¾›æ£€æŸ¥ç‚¹ä¿å­˜ã€åŠ è½½ã€æŸ¥æ‰¾ç­‰åŠŸèƒ½
2. model_pretrain.py æ·»åŠ æ—©åœæœºåˆ¶å¹¶ä¼˜åŒ–æ£€æŸ¥ç‚¹ç®¡ç†
- å®ç°æ—©åœæœºåˆ¶å‡½æ•°early_stoppingï¼Œç”¨äºç›‘æ§éªŒè¯æŒ‡æ ‡å¹¶åœ¨æ€§èƒ½ä¸å†æå‡æ—¶ç»ˆæ­¢è®­ç»ƒ
- ä¿®å¤æ£€æŸ¥ç‚¹ç›®å½•é…ç½®é”™è¯¯ï¼Œç»Ÿä¸€ä½¿ç”¨config.checkpoints_dir
- ä¼˜åŒ–æ£€æŸ¥ç‚¹ä¿å­˜é€»è¾‘ï¼Œä½¿ç”¨é…ç½®ä¸­çš„checkpoints_prefixä½œä¸ºå‰ç¼€
- è°ƒæ•´æœ€ä½³æ¨¡å‹ä¿å­˜ç­–ç•¥ï¼Œä½¿ç”¨config.checkpoints_monitorä½œä¸ºç›‘æ§æŒ‡æ ‡
- ç»Ÿä¸€ç¼“å­˜å‚æ•°é…ç½®å¹¶ç®€åŒ–æ•°æ®ç±»å‹è®¾ç½®
  - å°†key_cache_dtypeå’Œvalue_cache_dtypeåˆå¹¶ä¸ºcache_dtypeå‚æ•°
  - use_cacheé…ç½®é¡¹æ”¹ä¸ºä½¿ç”¨config.use_kvcache
3. configs/model_pretrain.yaml æ·»åŠ æ—©åœæœºåˆ¶å¹¶æ›´æ–°æ£€æŸ¥ç‚¹é…ç½®
- æ·»åŠ æ—©åœæœºåˆ¶ç›¸å…³å‚æ•°é…ç½®ï¼ŒåŒ…æ‹¬ç›‘æ§æŒ‡æ ‡ã€æ¨¡å¼å’Œæœ€å°æå‡å¹…åº¦
- æ›´æ–°æ£€æŸ¥ç‚¹é…ç½®ä¸­çš„ç›‘æ§æŒ‡æ ‡å’Œæ¨¡å¼ä¸º loss å’Œ min
4. datasets.py æ•°æ®é›†åŠ è½½å™¨æ–°å¢æµå¼æ•°æ®é›†ç±»æ”¯æŒå¤§æ–‡ä»¶å¤„ç†
- æ·»åŠ  StreamingPretrainDataset å’Œ StreamingSFTDataset ç±»ï¼Œæ”¯æŒæµå¼åŠ è½½ json/jsonl/csv æ ¼å¼æ•°æ®ï¼Œé¿å…å†…å­˜æº¢å‡ºé—®é¢˜ã€‚å®ç° IterableDataset æ¥å£ï¼Œé€æ¡è¯»å–å’Œå¤„ç†æ•°æ®ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡é¢„è®­ç»ƒå’Œå¾®è°ƒåœºæ™¯ã€‚
5. MultiHeadSelfAttention å®ç°KVç¼“å­˜æ”¯æŒåŠå¢é‡æ¨ç†åŠŸèƒ½
æ·»åŠ KVç¼“å­˜åŠŸèƒ½ä»¥æ”¯æŒè‡ªå›å½’ç”Ÿæˆï¼ŒåŒ…æ‹¬ï¼š
- å¼•å…¥ByteKVCacheç±»ç®¡ç†ç¼“å­˜çŠ¶æ€
- ä¿®æ”¹æ³¨æ„åŠ›æ©ç ç”Ÿæˆé€»è¾‘ä»¥æ”¯æŒç¼“å­˜åç§»
- å®ç°ç¼“å­˜åˆå§‹åŒ–ã€æ›´æ–°å’ŒçŠ¶æ€ç®¡ç†æ¥å£
- æ”¯æŒå¢é‡æ¨ç†æ—¶çš„ä½ç½®åç§»è®¡ç®—
- æ·»åŠ ç¼“å­˜ç›¸å…³æµ‹è¯•ç”¨ä¾‹
6. DecoderLayer æ·»åŠ å¯¹ByteKVCacheçš„æ”¯æŒå¹¶æ›´æ–°å‰å‘ä¼ æ’­
- ä¸ºDecoderLayeræ·»åŠ ByteKVCacheå‚æ•°æ”¯æŒï¼Œä¿®æ”¹å‰å‘ä¼ æ’­é€»è¾‘ä»¥å¤„ç†KVç¼“å­˜
7. Model æ·»åŠ KVç¼“å­˜æ”¯æŒä»¥æé«˜æ¨ç†æ€§èƒ½
- å¼•å…¥ByteKVCacheç±»æ¥ç¼“å­˜é”®å€¼å¯¹ï¼Œé¿å…åœ¨è‡ªå›å½’ç”Ÿæˆè¿‡ç¨‹ä¸­é‡å¤è®¡ç®—
- ä¿®æ”¹forwardæ–¹æ³•ä»¥æ”¯æŒç¼“å­˜ä¼ é€’
- åœ¨generateæ–¹æ³•ä¸­åˆå§‹åŒ–å¹¶ä½¿ç”¨ç¼“å­˜æ¥ä¼˜åŒ–é•¿åºåˆ—ç”Ÿæˆæ€§èƒ½ã€‚
8. KVCache æ·»åŠ é€»è¾‘å¤„ç†ç©ºåºåˆ—æ—¶è¿”å›ç©ºå¼ é‡
- å½“åºåˆ—é•¿åº¦ä¸º0æ—¶è¿”å›ç©ºå¼ é‡ä»¥é¿å…æ½œåœ¨é”™è¯¯
9. model/config.py ç»Ÿä¸€KVç¼“å­˜ç›¸å…³å‚æ•°å‘½å
- å°†`use_cache`é‡å‘½åä¸º`use_kvcache`ä»¥ä¿æŒå‘½åä¸€è‡´æ€§
- åˆå¹¶`key_cache_dtype`å’Œ`value_cache_dtype`ä¸º`cache_dtype`
10. configs/model_pretrain.yaml ç§»é™¤æ¨¡å‹é…ç½®ä¸­çš„KVç¼“å­˜å‚æ•°å¹¶é‡æ„ä¸ºç‹¬ç«‹æ¨¡å—
- å°†KVç¼“å­˜ç›¸å…³é…ç½®ä»æ¨¡å‹ä¸»é…ç½®ä¸­ç§»é™¤ï¼Œå¹¶é‡æ„ä¸ºç‹¬ç«‹çš„kv_cacheæ¨¡å—ï¼Œæé«˜é…ç½®çš„å¯è¯»æ€§å’Œæ¨¡å—åŒ–ç¨‹åº¦
11. MultiHeadSelfAttention å®Œå–„å¤šå¤´æ³¨æ„åŠ›æ¨¡å—çš„æ–‡æ¡£å’Œæ³¨é‡Š
- è¡¥å……ç±»å’Œæ–¹æ³•æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œè¯¦ç»†è¯´æ˜å‚æ•°å’Œè¿”å›å€¼
- æ·»åŠ å…³é”®æ­¥éª¤çš„ä»£ç æ³¨é‡Šï¼Œæé«˜å¯è¯»æ€§
- æ›´æ–°ç±»æ–‡æ¡£ä»¥åæ˜ æ–°å¢åŠŸèƒ½ç‰¹æ€§
12. MLP ä¼˜åŒ–MLPæ¨¡å—ç»“æ„å¹¶æ”¹è¿›æ–‡æ¡£è¯´æ˜
- å°†w13æ‹†åˆ†ä¸ºç‹¬ç«‹çš„w1å’Œw3çº¿æ€§å±‚ï¼Œæé«˜ä»£ç å¯è¯»æ€§
- é‡æ–°ç»„ç»‡å‰å‘ä¼ æ’­æ­¥éª¤ç¼–å·ï¼Œä½¿é€»è¾‘æ›´æ¸…æ™°
- å®Œå–„æ¨¡å—æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œè¡¥å……æ ¸å¿ƒç‰¹ç‚¹å’Œå‚æ•°è¯´æ˜
13. RMSNorm ä¼˜åŒ–æ–‡æ¡£æ³¨é‡Šå’Œä»£ç ç»“æ„
- é‡æ–°ç»„ç»‡å‡½æ•°å’Œç±»çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œä½¿å…¶æ›´æ¸…æ™°ç®€æ´
- ç»Ÿä¸€å‚æ•°å’Œè¿”å›å€¼çš„æè¿°æ ¼å¼
- ç§»é™¤å†—ä½™æ³¨é‡Šï¼Œä¿ç•™æ ¸å¿ƒåŠŸèƒ½è¯´æ˜
14. EmbeddingLayer å®Œå–„åˆ†å¸ƒå¼è¯åµŒå…¥å±‚çš„æ–‡æ¡£å’Œæ³¨é‡Š
- å¼ é‡å¹¶è¡Œè®¾è®¡åŸç†
- å‚æ•°å’Œè¿”å›å€¼çš„è¯¦ç»†æè¿°
- å…³é”®å®ç°ç»†èŠ‚çš„è§£é‡Š
- æƒé‡å…±äº«æ¥å£çš„ä½¿ç”¨åœºæ™¯
15. DecoderLayer é‡æ„è§£ç å™¨å±‚å®ç°å¹¶æ”¹è¿›æ–‡æ¡£
- é‡æ–°ç»„ç»‡ç±»æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œæ›´æ¸…æ™°åœ°è¯´æ˜å®ç°ç‰¹æ€§å’Œå‚æ•°
- ä¸ºå…³é”®å˜é‡æ·»åŠ æ³¨é‡Šè¯´æ˜å…¶ä½œç”¨
- ä¼˜åŒ–å‰å‘ä¼ æ’­é€»è¾‘çš„ä»£ç ç»“æ„ï¼ŒåŒºåˆ†å¹¶è¡Œå’Œé¡ºåºæ¨¡å¼
- æ”¹è¿›å˜é‡å‘½åå’Œä»£ç æ ¼å¼ï¼Œå¢å¼ºå¯è¯»æ€§
16. Model é‡æ„æ¨¡å‹ä»£ç å¹¶æ·»åŠ è¯¦ç»†æ–‡æ¡£æ³¨é‡Š
- æ·»åŠ ç±»å’Œæ–¹æ³•çº§åˆ«çš„è¯¦ç»†æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œè¯´æ˜æ¶æ„å’ŒåŠŸèƒ½
- é‡æ–°ç»„ç»‡ä»£ç ç»“æ„ï¼Œå¢åŠ æ¨¡å—åˆ†éš”æ³¨é‡Š
- ä¼˜åŒ–æƒé‡åˆå§‹åŒ–é€»è¾‘ï¼Œæ·»åŠ ç¼©æ”¾å› å­è¯´æ˜
- æ”¹è¿›å‰å‘ä¼ æ’­å’Œç”Ÿæˆæ–¹æ³•çš„å®ç°ç»†èŠ‚
- å¢å¼ºé‡‡æ ·æ–¹æ³•çš„å¯è¯»æ€§å’Œæ³¨é‡Š
17. DropPath æ›´æ–°å®Œå–„DropPathæ¨¡å—çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œè¡¥å……åŠŸèƒ½ç‰¹æ€§è¯¦ç»†è¯´æ˜å’Œå‚æ•°æ³¨é‡Š
18. KVCache å®Œå–„ç±»å’Œæ–¹æ³•æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œå¢åŠ è¯¦ç»†è¯´æ˜å’Œå¼‚å¸¸æè¿°
- ç±»åŠŸèƒ½ç‰¹æ€§çš„è¯¦ç»†è¯´æ˜
- æ–¹æ³•å‚æ•°å’Œè¿”å›å€¼çš„å®Œæ•´æè¿°
- å¯èƒ½æŠ›å‡ºçš„å¼‚å¸¸ç±»å‹åŠè§¦å‘æ¡ä»¶
- å†…éƒ¨å®ç°ç»†èŠ‚çš„è¡¥å……è¯´æ˜
- åˆ†å¸ƒå¼æ“ä½œå’ŒçŠ¶æ€ç®¡ç†çš„æ–‡æ¡£å®Œå–„
19. tokenizer_pretrain.py ä¼˜åŒ–tokenizeré…ç½®å’Œé¢„å¤„ç†é€»è¾‘
- é‡æ–°ç»„ç»‡tokenizeré…ç½®é¡¹é¡ºåºï¼Œå°†tokenizer_classç§»è‡³é¡¶éƒ¨
- ç§»é™¤å†—ä½™çš„sep_tokenï¼Œç®€åŒ–ç‰¹æ®Štokenåˆ—è¡¨
- æ”¹è¿›æ–‡æœ¬è§„èŒƒåŒ–é€»è¾‘ï¼Œç»Ÿä¸€æ•°å­—å¤„ç†ä¸º[NUMBER]
- ä¼˜åŒ–é¢„åˆ†è¯å™¨è§„åˆ™ï¼Œä¸“æ³¨äºä»£ç ç¬¦å·å’Œå¤§å°å†™å¤„ç†
- è°ƒæ•´ç‰¹æ®Štokençš„IDæ˜ å°„ä»¥ä¿æŒä¸€è‡´æ€§

### TODO
1. å°è¯•è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œå¹¶å¯»æ‰¾BUG
2. ä¼˜åŒ–MLPå±‚ï¼Œå°è¯•åŠ å…¥èåˆæ¨ç†
3. æµ‹è¯•KVCache
4. åˆ†æå¹¶ä¼˜åŒ–æ˜¾å­˜å ç”¨
5. å¯»æ‰¾å¹¶æ„å»ºtokenizerè®­ç»ƒæ•°æ®é›†
  - ä¸­æ–‡è¯­æ–™
  - è‹±æ–‡è¯­æ–™
  - Emojiè¯­æ–™
  - Codeè¯­æ–™
6. å¯»æ‰¾å¹¶æ„å»ºæ¨¡å‹è®­ç»ƒæ•°æ®é›†
  - æ–‡æœ¬ç”Ÿæˆ
  - ä»£ç ç”Ÿæˆ/ä»£ç ç†è§£
  - é€»è¾‘æ¨ç†/é—®ç­”/å¸¸è¯†
  - å¤šè½®å¯¹è¯

</details>

---

<details>
<summary>2025.8.15</summary>

### DONE
1. ç§»é™¤MoERouter.pyæ–‡ä»¶åŠå…¶ç›¸å…³å®ç°
2. MoELayer å®ç°åˆ†å¸ƒå¼ä¼˜åŒ–çš„MoEå±‚å¹¶æ”¯æŒall_to_allé€šä¿¡
- é‡æ„MoEå±‚ä¸ºåˆ†å¸ƒå¼ä¼˜åŒ–ç‰ˆæœ¬ï¼Œæ”¯æŒå¤šGPUä¸“å®¶å¹¶è¡Œè®¡ç®—
- ä½¿ç”¨å‘é‡åŒ–top-kè·¯ç”±å’Œå®¹é‡æ§åˆ¶æœºåˆ¶
- å®ç°åŸºäºall_to_allçš„åˆ†å¸ƒå¼tokenäº¤æ¢
- ä¿ç•™è´Ÿè½½å‡è¡¡lossä»¥ä¼˜åŒ–ä¸“å®¶åˆ©ç”¨ç‡

### TODO
1. æµ‹è¯• MoELayer å¹¶ä¿®å¤å¯¹åº”BUG
2. å°è¯•ä½¿ç”¨ MoELayer æ›¿æ¢ MLP
3. ä¼˜åŒ– MoELayer
4. ä½¿ç”¨æµå¼æ•°æ®é›†åŠ è½½å™¨æ›¿æ¢å…¨é‡æ•°æ®é›†åŠ è½½å™¨è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œè¿›è¡Œæµ‹è¯•ï¼Œå¹¶ä¿®å¤å¯¹åº”BUG

</details>

---

<details>
<summary>2025.8.16</summary>

### DONE
1. model_pretrain.py æ·»åŠ æ•°æ®é›†æµå¼åŠ è½½æ”¯æŒ
- ä¸ºå¤§è§„æ¨¡æ•°æ®é›†è®­ç»ƒæ·»åŠ æµå¼åŠ è½½åŠŸèƒ½ï¼Œé€šè¿‡é…ç½®use_streamingå¼€å…³æ§åˆ¶åŠ è½½æ–¹å¼ã€‚å½“å¯ç”¨æµå¼åŠ è½½æ—¶ï¼Œä½¿ç”¨StreamingPretrainDatasetå’Œisliceè¿›è¡Œåˆ†æ‰¹å¤„ç†ï¼Œé¿å…å†…å­˜ä¸è¶³é—®é¢˜å¹¶æ”¯æŒæ›´å¤§è§„æ¨¡æ•°æ®è®­ç»ƒã€‚åŒæ—¶è°ƒæ•´äº†ç›¸å…³è®­ç»ƒé€»è¾‘å’Œå‚æ•°è®¡ç®—ä»¥é€‚åº”æµå¼åŠ è½½æ¨¡å¼ã€‚
2. configs/model_pretrain.yaml æ›´æ–°æ¨¡å‹é¢„è®­ç»ƒé…ç½®æ–‡ä»¶ï¼Œæ·»åŠ æµå¼è®­ç»ƒç›¸å…³å‚æ•°
- æ·»åŠ æµå¼è®­ç»ƒç›¸å…³é…ç½®å‚æ•°ï¼ŒåŒ…æ‹¬use_streamingã€steps_per_epochç­‰
- è°ƒæ•´batch_sizeå‚æ•°ä½ç½®è‡³æ•°æ®é›†åŠ è½½å™¨éƒ¨åˆ†
- è¡¥å……æ¢¯åº¦ç´¯ç§¯æ­¥æ•°çš„æœ‰æ•ˆbatch_sizeè®¡ç®—å…¬å¼
3. datasets æ•°æ®é›†åŠ è½½å™¨æ·»åŠ åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒå¹¶æ·»åŠ æµå¼æ•°æ®åŠ è½½é€»è¾‘
- åœ¨BaseDatasetä¸­æå–_format_sampleæ–¹æ³•é¿å…ä»£ç é‡å¤
- ä¸ºStreamingPretrainDatasetå’ŒStreamingSFTDatasetæ·»åŠ åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ
- å°†æ•°æ®ç¼–ç é€»è¾‘é‡æ„ä¸º_encode_oneæ–¹æ³•æé«˜å¯ç»´æŠ¤æ€§

### TODO
1. é‡æ„MoELayerï¼Œæ·»åŠ æµå¼tokenåˆ†å‘å’Œä¸“å®¶å¹¶è¡Œæ”¯æŒï¼Œä½¿ç”¨all_to_allé€šä¿¡æ¨¡å¼ï¼Œæ”¯æŒé«˜æ•ˆtokenåˆ†å‘å’Œè®¡ç®—
- æ”¯æŒå¤šGPUä¸“å®¶å¹¶è¡Œè®¡ç®—
- å®ç°åˆ†å¸ƒå¼top-kè·¯ç”±å’Œä¸“å®¶è´Ÿè½½å‡è¡¡
- ä¿æŒæ˜¾å­˜å’Œgpuå ç”¨ç¨³å®šã€‚
2. é‡æ„MoELayeræµ‹è¯•æ¨¡å—ï¼Œå¹¶ä¿®å¤å¯¹åº”BUGã€‚

</details>

---

<details>
<summary>2025.8.18</summary>

### DONE
1. ByteMoELayer é‡æ„MoEå±‚å®ç°ï¼Œå¢åŠ ä¸“å®¶å¹¶è¡Œæ”¯æŒå¹¶ä¼˜åŒ–é€šä¿¡æ•ˆç‡ï¼š
- å®ç°åŒall_to_allé€šä¿¡æ¨¡å¼ï¼Œæ”¯æŒé«˜æ•ˆåˆ†å¸ƒå¼tokenåˆ†å‘ä¸ç»“æœèšåˆ
- æ”¹è¿›è·¯ç”±ç®—æ³•ï¼Œæ”¯æŒtop-1/top-2è·¯ç”±åŠå®¹é‡è£å‰ª
- å¢å¼ºä¸“å®¶æ¨¡å—åŠŸèƒ½ï¼Œæ”¯æŒæ®‹å·®è¿æ¥å’ŒLayerNorm
- ä¼˜åŒ–è´Ÿè½½å‡è¡¡æŸå¤±è®¡ç®—ï¼Œæé«˜ä¸“å®¶åˆ©ç”¨ç‡
- å®Œå–„å•å¡/å¤šå¡å…¼å®¹æ€§å¤„ç†

### TODO
1. é‡æ„ByteMoELayeræµ‹è¯•æ¨¡å—ï¼Œå¹¶ä¿®å¤å¯¹åº”BUG
2. å°è¯•åº”ç”¨ByteMoELayeræ›¿ä»£MLP

</details>

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç ã€æŠ¥å‘Šé—®é¢˜æˆ–æå‡ºæ–°åŠŸèƒ½å»ºè®®ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºæ‚¨çš„ç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤æ‚¨çš„æ›´æ”¹ (`git commit -m 'Add some amazing feature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. æ‰“å¼€ä¸€ä¸ª Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ CC BY-NC 4.0 è®¸å¯è¯ - è¯¦æƒ…è¯·å‚é˜… [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ“– å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶æˆ–é¡¹ç›®ä¸­ä½¿ç”¨äº†æœ¬ä»“åº“ï¼Œè¯·æŒ‰ä»¥ä¸‹æ–¹å¼å¼•ç”¨ï¼š

```bibtex
@misc{StellarByte,
  author       = {Yao Xiang Zhang},
  title        = {StellarByte},
  year         = {2025},
  publisher    = {GitHub},
  journal      = {GitHub repository},
  howpublished = {\url{https://github.com/HxCodeWarrior/StellarByte}}
}
```

---

## ğŸŒŸ è‡´è°¢

- æ„Ÿè°¢æ‰€æœ‰ä¸º Transformer æ¶æ„å‘å±•åšå‡ºè´¡çŒ®çš„ç ”ç©¶è€…
- æ„Ÿè°¢ HuggingFace å›¢é˜Ÿæä¾›çš„å‡ºè‰²å·¥å…·å’Œç”Ÿæ€ç³»ç»Ÿ
- æ„Ÿè°¢æ‰€æœ‰é¡¹ç›®è´¡çŒ®è€…

---

<div align="center">
  <sub>æŠŠæ¯ä¸ªå­—èŠ‚éƒ½ç‚¹äº®æˆä¸€ç›ç¯ï¼Œç…§è§å¤ä»ŠåŒæœ›çš„å¤œç©ºã€‚</sub>
</div>